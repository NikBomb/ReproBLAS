\subsection{Sum}
  \label{sec:primitiveops_sum}
    Algorithm \ref{alg:sum} is an indexed summation algorithm that allows the user to efficiently add a vector of floating point numbers $x_m, ..., x_{m + n - 1} \in \F$ to the indexed sum $Y$ of some $x_0, ..., x_{m - 1} \in F$.

    As mentioned in Section~\ref{sec:primitiveops_renormalize}, it is not necessary to perform
    a renormalization for every deposit, as would be done if Algorithm \ref{alg:addfloattoindexed} were applied iteratively on each element of $x_m, ..., x_{m + n -1}$. At most $2^{p-W-2}$ values can be deposited in the indexed type before having to perform the renormalization.
    Therefore we have an improved version of Algorithm~\ref{alg:addfloattoindexed} when we need to sum a vector of floating point numbers.
    Algorithm~\ref{alg:sum} summarizes the optimized version for the reproducible local sum. It is available as \texttt{idxdBLAS_xixsum} in \texttt{idxdBLAS.h} in ReproBLAS.
    As Algorithm~\ref{alg:sum} computes an indexed sum, it can be performed on the $x_m, ..., x_{m + n - 1}$ in any order. However, for the simplicity of presenting the algorithm, it is depicted as running linearly from $m$ to $m-1$.
    Algorithm \ref{alg:sum} uses only one indexed type to hold the intermediate result of the recursive summation, and the vast majority of time in the algorithm is spent in the deposit routine.
    \begin{samepage}
    \begin{alg}
      If $Y$ is the $K$-fold indexed sum of some $x_0, ..., x_{m - 1} \in \F$, produce the $K$-fold indexed sum of $x_0, ..., x_{m + n - 1} \in \F$.
      This is similar to Algorithm $6$ in \cite{repsum}, but requires no restrictions on the size or type (exceptional or finite) of inputs $x_0, ..., x_{m + n - 1}$.
      \begin{algorithmic}[1]
        \Function{Sum}{$K$, [$x_m, ..., x_{m + n-1}$], $Y$}
          \State $j = 0$ \label{alg:sum:setj}
          \While{$j < n$}\label{alg:sum:outerloop}
            \State $nb = \min(n, j + 2^{p - W - 2})$
            \State \Call{Update}{$K$, $\max([|x_{m + j}|, ..., |x_{m + nb - 1}|)$, Y}\label{alg:sum:update}
            \While{$j < nb$}
              \State \Call{Deposit}{$K$, $x_{m + j}$, $Y$}\label{alg:sum:deposit}
              \State $j = j + 1$
            \EndWhile
            \State \Call{Renorm}{$K$, $Y$}\label{alg:sum:renorm}
          \EndWhile
          \State \Return $Y$
        \EndFunction
        \Ensure
        \Statex $Y$ is the unique indexed sum of $x_0, ..., x_{m + n - 1}$.
      \end{algorithmic}
      \label{alg:sum}
    \end{alg}
    \end{samepage}
    If a single floating point result is desired, it may be obtained from $Y$ using Algorithm \ref{alg:conv2floatoverflow} described in Section \ref{sec:primitiveops_conv2float}.
    \begin{samepage}
    \begin{thm}
      Assume that we have run Algorithm \ref{alg:sum} on the $K$-fold indexed sum $Y$ of $x_0, ..., x_{m - 1} \in \F$ and on $x_m, ..., x_{m + n - 1} \in \F$. If all requirements of the algorithm are satisfied, then the ``Ensure'' claim at the end of the algorithm holds.
      \label{thm:sum}
    \end{thm}
    \end{samepage}
    \begin{proof}
      We show inductively that after each execution of line \ref{alg:sum:renorm}, $Y$ is the indexed sum of $x_0, ..., x_{m + j - 1}$. Throughout the proof, assume that the value of all variables are specific to the given stage of execution.

      As a base case, on the first iteration of the loop on line \ref{alg:sum:outerloop}, $j$ is 0 and $Y$ is given to be the indexed sum of $x_0, ..., x_{m - 1}$.

      In subsequent iterations of the loop, we assume that at line \ref{alg:sum:update}, $Y$ is the indexed sum of $x_0, ..., x_{m + j - 1}$.

      In this case, the proof of Theorem \ref{thm:addfloattoindexed} applies to lines \ref{alg:sum:update} to \ref{alg:sum:renorm} (keeping in mind that at most $2^{p - W - 2}$ deposits are performed and by the ``Ensure'' claim of Algorithm \ref{alg:update}, each finite $x_{m + j}$ deposited satisfies $|x_{m + j}| < 2^{b_I}$). Therefore, after line \ref{alg:sum:renorm}, $Y$ is the indexed sum of $x_0, ..., x_{m + j - 1}$

      \begin{comment}
        Therefore ${Y_k}_P \in [1.5  \epsilon^{-1} 2^{a_{I + k}}, 1.75  \epsilon^{-1} 2^{a_{I + k}})$ unless $I + k = 0$, in which case ${Y_0}_P \in (2^{e_{\max}}, 2 \cdot 2^{e_{\max}})$.

      In either case, the ``Require'' clause of Algorithm \ref{alg:update} is satisfied. Therefore, after executing line \ref{alg:sum:update}, the following statements hold:
      \begin{enumerate}
      \item
        The index of $Y$ is $I$ where $I$ is the greatest integer such that $\max(|x_0|, ..., |x_{m - 1}|) < 2^{b_I}$
      \item
        $\mathcal{Y}_k = d(x_0, I + k) + ... + d(x_{j - 1}, I + k)$
      \item
        \Statex ${Y_k}_P \in [1.5  \epsilon^{-1} 2^{a_{I + k}}, 1.75  \epsilon^{-1} 2^{a_{I + k}})$ unless $I + k = 0$, in which case ${Y_0}_P \in (2^{e_{\max}}, 2 \cdot 2^{e_{\max}})$
      \end{enumerate}
      Between lines \ref{alg:sum:innerloop} and \ref{alg:sum:innerloopend}, at most $0.25\epsilon^{-1}2^{-W}$ calls to \ref{alg:sum:deposit} are made, and by Theorem \ref{thm:depositfreq}, and the above initial properties, the requirements of Algorithm \ref{alg:deposit} are met at each call. Therefore, after line \ref{alg:sum:innerloopend}, we have that $\mathcal{Y}_k = d(x_0, I + k) + ... + d(x_{j-1}, I + k)$.

      Again by Theorem \ref{thm:depositfreq}, the requirements of Algorithm \ref{alg:renorm} are met in line \ref{alg:sum:renorm}. Therefore, after execution of line \ref{alg:sum:renorm}, we have that ${Y_k}_P \in [1.5  \epsilon^{-1} 2^{a_{I + k}}, 1.75  \epsilon^{-1} 2^{a_{I + k}})$ unless $I + k = 0$, in which case ${Y_0}_P \in (1.5 \cdot 2^{e_{\max}}, 1.75 \cdot 2^{e_{\max}})$. Therefore, $Y$ is the indexed sum of $x_0, ..., x_{j - 1}$ after line \ref{alg:sum:renorm}, completing the induction.
      \end{comment}
    \end{proof}
    As the indexed sum is unique and independent of the ordering of its summands (Theorem \ref{thm:indexed_sum_unique}), Algorithm \ref{alg:sum} is reproducible up to permutation of its inputs.

    Even in the absence of an operation for reduction, Algorithm \ref{alg:sum} is already a highly flexible operation.
    Consider the problem of computing a reproducible dot product of vectors $\vec{x}$ and $\vec{y}$. To modify algorithm for this purpose, we need only change line \ref{alg:sum:deposit} to deposit the product of the $j^{th}$ entry of $\vec{x}$ and the $j^{th}$ entry of $\vec{y}$. More examples of how this routine can be used for reproducible operations are given in Section \ref{sec:compositeops}.

    At this point, an analysis of runtime should be considered. Since Algorithm~\ref{alg:sum} only performs the update and renormalization
  once for every $2^{p-W-2}$ times the deposit operation is performed (that
s $2^{53-40-2}=2^{11}$ times for double precision and $2^{24-13-2} = 2^9$ times for single precision in the current implementation of
  ReproBLAS), the cost of Algorithm~\ref{alg:sum} is mostly due to the
  deposit operation.
  Therefore, in the absence of overflow, Algorithm~\ref{alg:sum} costs
  $\approx (3K-1)n$ FLOPs counting the maximum absolute value operation as 1 FLOP,
  which is $\approx 7Kn$ FLOPs for the default value of $K$ ($K=3$) used by ReproBLAS.
  In the rare case of index 0 for the first bin,
  the cost is slightly higher since the first bin
  needs to be scaled down to avoid overflow, which increases the
  total cost of Algorithm~\ref{alg:sum} to $\approx (3K+2)n$ FLOPs.










\begin{comment}

  Based on the operations presented above, in this section we will describe algorithms
  to reproducibly compute a local sum of a floating-point input vector.
  Algorithm~\ref{alg:naive-local-sum} depicts a naive implementation of the
  local reproducible sum, which does not require to know about the input data beforehand.
  An improved version of this algorithm will be described shortly after.

  \begin{alg}
    Naive local reproducible sum of floating-point numbers
    \label{alg:naive-local-sum}
    \begin{algorithmic}[1]
      \Require
        $x = [x_0, ..., x_{n - 1}], x_i \in F$.
        $Y$ is an indexed sum.
        $K \in \Z, K > 1$ is the fold.
      \Function{NaiveLocalSum}{x}
        \State $[{Y_0}_P, ..., {Y_{K - 1}}_P, {Y_0}_C, ..., {Y_{K - 1}}_C] = [0, ..., 0]$
        \Comment{Initialization}
        \For {$i \in [0, \ldots, n-1]$ in any order}
          \State \Call{Update}{K, $x_i$, $Y$}
          \Comment{Adjust index of $Y$}
          \State \Call{Deposit}{K, $x_i$, $Y$}
          \Comment{Add slices of $x$ to corresponding bins}
          \State \Call{Renorm}{K, $Y$}
          \Comment{Carry-bit propagation}
        \EndFor
        \State \Return $Y$
      \EndFunction
      \Ensure
        \Statex $Y$ is the $K$-fold indexed sum of $x_0, ..., x_{n - 1}$.
    \end{algorithmic}
  \end{alg}

  We will now prove the reproducibility of Algorithm~\ref{alg:naive-local-sum}.
  We first state the reproducibility of the index of computed result by
  Lemma~\ref{lem:reproducible-index}.
  \begin{lem}
    Let $Y$ be the indexed-type computed by Algorithm~\ref{alg:naive-local-sum},
    then
    \(
      \mathtt{IIndex}(Y) = \min_{i=0}^{n-1} \mathtt{Index}(x_i),
    \)
    and $\mathtt{IIndex}(Y)$ is reproducible.
    \label{lem:reproducible-index}
  \end{lem}
  \begin{proof}
    This lemma is the direct result of the updating process.
    Since the \fct{Deposit} and \fct{Renorm} functions do not alter
    the index of $Y$, after each iteration of the Algorithm~\ref{alg:naive-local-sum},
    the index of $Y$ is updated to the value of $\min(\fct{IIndex}(Y), \fct{Index}(x_i))$.
    Since $Y$ is first initialized to $0$, 
    and the minimum value operation is associative, we have
    \(
      \fct{IIndex}(Y) = \min_{i=0}^{n-1} \fct{Index}(x_i),
    \)
    which is by consequence reproducible.
  \end{proof}

    Lemma~\ref{lem:reproducible-index} also means that $\fct{IIndex}(Y) = \fct{Index}(\max |x_i|)$
    if $\max |x_i|$ is not NaN or infinity.

  \begin{lem}
    Let $Y$ be the indexed-type computed by Algorithm~\ref{alg:naive-local-sum},
    if $n \leq 2^{2p -W - 2}$, then the accumulators of $Y$ are exactly computed.
    \label{lem:exact-local-Y}
  \end{lem}
  \begin{proof}
    Let $I$ be the index of the computed $Y$ of Algorithm~\ref{alg:naive-local-sum}.
    According to Lemma~\ref{lem:reproducible-index}, $I$ is reproducible.
    Moreover, $\fct{IIndex}(Y) = \min_{i=0}^{n-1} \mathtt{Index}(x_i)$,
    therefore $|x_i| < 2^{b_I}$ for all $0 \leq i < n$.
    Since the $\fct{Deposit}$ function takes care of adding input slices
    to corresponding bins, in this proof, we're only interested in bins of
    indices $I, \ldots, I+K-1$ in the final computed result.
    For simplicity, we assume that $I+K-1 \leq i_{max}$, since values smaller
    than $2^{a_{i_{max}}}$ won't contribute to the final result.

    With the \fct{Update} function, all the accumulators of $Y$ will alays be initialized
    with ${Y_k}_P = 1.5 \epsilon^{-1} 2^{a_{I+k}}$ and ${{Y_k}}_C = 0$.
    Moreover, the call to \fct{Renorm} function at the end of each iteration
    ensures that the primary field of each accumulator ${Y_k}_P$ once initialized
    will always be in the range
    $[1.5 \epsilon^{-1} 2^{a_{I+k}}, 1.75 \epsilon^{-1} 2^{a_{I+k}})$.
    This is the condition for \fct{Deposit} function to be correctly performed.

%    We will prove by induction that there will be no overflow in ${Y_k}_C$.
%    It is trivial for the base case of the first iteration.
%    Let's assume that $Y$ is exactly computed at the end of the $j$-th iteration ($0 < j < n-1$).
    Each accumulator $Y_k$ of $Y$ accumulates slices $d(x_i, I + k)$ of input values.
    The exact value of $Y_k$ after $j \leq n$ iterations is:
    \begin{equation}
        \mathcal{\hat{Y}}_k = ({\hat{Y_k}}_P - 1.5 \epsilon^{-1}2^{a_{I+k}}) + (0.25\epsilon^{-1} 2^{a_{I+k}}) \hat{Y_k}_C
        = \sum_{i=0}^{j} d(x_i, I + k)
        \label{eq:exact-Ykj}
    \end{equation}
    By Theorem \ref{thm:ddeposit}, we have 
    \begin{equation}
      |\mathcal{\hat{Y}}_k| \leq \sum_{i=0}^{j} |d(x_i, I + k)| \leq j 2^{b_{I+k}} < n 2^W 2^{a_{I+k}}
      \leq 2^{2p-2} 2^{a_{I+k}}
      \label{eq:bounded-Ykj}
    \end{equation}
    Moreover, ${Y_k}_P$ is always exactly computed, which means ${Y_k}_P = \hat{Y_k}_P$ and
    \(
        \hat{Y_k}_P - 1.5 \epsilon^{-1}2^{a_{I+k}} \in [0, 0.25 \epsilon^{-1} 2^{a_{I+k}}).
    \)
    Therefore
    \begin{equation}
        -2^{2p-2} 2^{a_{I+k}} -  0.25 \epsilon^{-1} 2^{a_{I+k}} < (0.25\epsilon^{-1} 2^{a_{I+k}}) \hat{Y_k}_C
            \leq 2^{2p-2} 2^{a_{I+k}}.
            \label{eq:bounded-YCkj}
    \end{equation}
    It means that $-2^p - 1 < \hat{Y_k}_C \leq 2^p$.
    Since $\hat{Y_k}_C \in \Z$, we have $-2^p \leq \hat{Y_k}_C \leq 2^p$. So the exact value of the primary field
    of each accumulator will never overflow.
    After each renormalization, the carry field of each accumulator is only incremented or decremented by 1,
    whose exact value does not overflow.
    Therefore the carry fields of $Y$ are always exactly computed when $n \leq 2^{2p-W -2}$.
    The proof is complete.
  \end{proof}

    Note that in the above proof, if $n < 2^{2p-W-1}$ then the last inequalities in equations \eqref{eq:bounded-Ykj}
    and \eqref{eq:bounded-YCkj} are strict, which means
    \begin{equation}
        -2^p \leq {Y_k}_C < 2^p \quad \text{ when } n < 2^{2p-W-2}
    \end{equation}

    Lemma~\ref{lem:reproducible-index} and \ref{lem:exact-local-Y} provide the reproducibility
    of Algorithm~\ref{alg:naive-local-sum}.
    As mentioned in Section~\ref{sec:primitiveops_renormalize}, it is not necessary to perform
    the renormalization for every addition. At most $2^{p-W-2}$ values can be added to each
    accumulator before having to perform the renormalization.
    Therefore we have an improved version of Algorithm~\ref{alg:naive-local-sum}.
    Algorithm~\ref{alg:local-sum} summarizes the optimized version for the reproducible local sum,
    which is implemented as functions $\mathtt{idxdBLAS\_dsum}$, $\mathtt{idxdBLAS\_ssum}$
    in Section~\ref{sec:idxdBLAS}.
    Similarly to Algorithm~\ref{alg:naive-local-sum}, Algorithm~\ref{alg:local-sum} can be performed
    in any order. However, for the simplicity of presenting the algorithm, it is depicted
    as running linearly from $0$ to $n-1$.

  \begin{alg}
    Local reproducible sum of floating-point numbers
    \label{alg:local-sum}
    \begin{algorithmic}[1]
      \Require
        $x = [x_0, ..., x_{n - 1}], x_i \in F$.
        $Y$ is an indexed sum.
        $K \in \Z, K > 1$ is the fold.
      \Function{LocalSum}{x}
        \State $[{Y_0}_P, ..., {Y_{K - 1}}_P, {Y_0}_C, ..., {Y_{K - 1}}_C] = [0, ..., 0]$
        \Comment{Initialization}
        \State $IB = 0$
        \State $NB = 2^{p-W-2}$
        \While {$IB < n$}
          \State $m = \max_{i=IB}^{\min(IB+NB,n)-1} |x_i|$
            \Comment{Local maximum}
          \State \Call{Update}{K, m, $Y$}
          \Comment{Adjust index of $Y$}
          \For {$i$ from $IB$ \To $\min(IB+NB,n)-1$}
              \State \Call{Deposit}{K, $x_i$, $Y$}
              \Comment{Add slices of $x_i$ to corresponding bins}
          \EndFor
          \State \Call{Renorm}{K, $Y$}
          \Comment{Carry-bit propagation}
          \State $IB = IB + NB$
        \EndWhile
        \State \Return $Y$
      \EndFunction
      \Ensure
        \Statex $Y$ is the $K$-fold indexed sum of $x_0, ..., x_{n - 1}$.
    \end{algorithmic}
  \end{alg}

  \begin{thm}
    Let $n \in \Z$ and $n \leq 2^{2p-W-2}$ then the result computed by Algorithm~\ref{alg:local-sum} is reproducible.
  \end{thm}
  \begin{proof}
    The inner loop of Algorithm~\ref{alg:local-sum} (line 8--10) performs at most $NB=2^{p-W-2}$ deposits
    before each renormalization, therefore the \fct{Deposit} function call is always executed correctly.
    The rest of the proof is similar to the proof for the reproducibility of Algorith~\ref{alg:naive-local-sum}.
  \end{proof}

  Since Algorithm~\ref{alg:local-sum} only performs the update and renormalization
  every $2^{p-W-2} iterations$, which is $2^{53-40-2}=2^{11}$ for double precision and
  $2^{24-13-2} = 2^9$ for single precision in the current implementation of
  ReproBLAS, the cost of Algorithm~\ref{alg:local-sum} is mostly due to the
  deposit operation.
  Therefore, in the absence of overflow, Algorithm~\ref{alg:local-sum} costs
  $\approx (3K-1)n$ FLOPs counting the maximum absolute value operation as 1 FLOP,
  which is $\approx 7Kn$ FLOPs for the default fold $K=3$ of ReproBLAS.
  In the rare case of index 0 for the first bin,
  the cost is slightly higher since the first bin
  needs to be scaled down to avoid overflow, which increases the
  total cost of Algorithm~\ref{alg:local-sum} to $\approx (3K+2)n$ FLOPs.
\end{comment}

