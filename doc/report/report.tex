\documentclass[12pt]{article}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{tikz}
\pagestyle{myheadings}

\author{Peter Ahrens, Hong Diep Nguyen, James Demmel}
\title{ReproBLAS: Much Summation! So Reproducible!}
\providecommand{\ceil}[1]{\left \lceil #1 \right \rceil }
\providecommand{\floor}[1]{\left \lfloor #1 \right \rfloor }
\providecommand{\R}{\ensuremath{\mathbb{R}}}
\providecommand{\F}{\ensuremath{\mathbb{F}}}
\providecommand{\Z}{\ensuremath{\mathbb{Z}}}
\providecommand{\exp}{\ensuremath{\text{exp}}}
\providecommand{\min}{\ensuremath{\text{min}}}
\providecommand{\max}{\ensuremath{\text{max}}}
\providecommand{\ulp}{\ensuremath{\text{ulp}}}
\providecommand{\ufp}{\ensuremath{\text{ufp}}}
\providecommand{\fl}{\ensuremath{\text{fl}}}
\providecommand{\roundtonearestinfty}{\ensuremath{\text{round}_\text{to nearest, $\infty$}}}
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{alg}{Algorithm}[section]
\newtheorem{eq}{Equation}[section]
\graphicspath{{plots}}
\begin{document}
\noindent
\maketitle
\tableofcontents
\newpage
\section{Introduction}

\section{Notation and Background}
  Let $\R, \F, $ and $\Z$ denote the sets of real numbers, floating-point numbers, and integers respectively.

  Assume that floating point arithmetic complies with the IEEE 754-2008 standard \cite{ieee754} in "to nearest even" rounding mode and that underflow occurs gradually.

  Let $f = s \times 2^e \times m \in \F$ be a floating-point number represented in IEEE 754-2008 format \cite{ieee754} where $s = \pm 1$ is the \textbf{sign}, $e_{\max} \geq e \geq e_{\min}$ is the \textbf{exponent} ($\exp(f)$ is defined to be $e$), $p$ is the \textbf{precision}, and $m = m_0.m_1m_2...m_{p-1}$ where $m_1, ..., m_{p - 1} \in \{0, 1\}$ is the \textbf{significand} of $f$. $f$ is said to be \textbf{normalized} if $m_0 = 1$ and $e > e_{\min}$, \textbf{unnormalized} if $m_0 = 0$, and \textbf{subnormal} if $m_0 = 0$ and $e = e_{\min}$. $f = 0$ if $m_0 = m_1 = ... = m_{p - 1} = 0$ and $e = e_{\min}$.

  Machine epsilon, $\epsilon$, the difference between 1 and the largest floating point number smaller than 1, is defined as $\epsilon = 2^{-p}$.

  The unit in the last place of $f \in \F$, $\ulp(f)$, is the spacing between two consecutive floating point numbers of the same exponent as $f$. If $f$ is normalized, $\ulp(f) = 2^{\exp(f) - p + 1} = 2 \times \epsilon \times 2^{\exp(f)}$.

  The unit in the first place of $f \in F$, $\ufp(f)$, is the value of the first significant bit of $f$. If $f$ is normalized, $\ufp(f) = 2^{\exp(f)}$.

  $\fl(\dot)$ denotes the evaluated result of an expression in floating point arithmetic.

  We define the function $\roundtonearestinfty(x, 2^k), x \in R, k \in \Z$ as

  $\roundtonearestinfty(x, 2^k) = \begin{cases}\floor{x/2^k + 1/2} \times 2^k \text{ if } x \geq 0\\ \\ \ceil{x/2^k - 1/2}\times 2^k \text{ otherwise}\end{cases}$

  $\roundtonearestinfty(x, 2^k)$ rounds $x$ to the nearest multiple of $2^k$, breaking ties away from 0.

  As ReproBLAS is written in C, \verb|float| and \verb|double| refer to the floating point types specified in the 1989 C standard \cite{c89} and we assume that they correspond to the \verb|binary-32| and \verb|binary-64| types in the IEEE 754-2008 floating point standard \cite{ieee754}.

  All indices start at $0$ in correspondence with the actual ReproBLAS implementation.

\section{The Indexed Type}
  \subsection{Representation}
    The \textbf{indexed type} is used to represent the intermediate result of accumulation using Algorithms 6 and $7$ in \cite{repsum}.
    An indexed type $Y$ is a data structure composed of several accumulator data structures $Y_0, ..., Y_{fold - 1}$. The number of accumulators in an indexed type is referred to as its \textbf{fold}. Due to their wild inaccuracy, indexed types of fold 1 are not considered.

    Let $Y$ be the indexed type corresponding to the reproducibly computed sum of $x_0, ..., x_{n - 1} \in F$.
    Each accumulator $Y_j$ accumulates input in a \textbf{bin} $(a_j, b_j], a < b \in \Z$. The real number value $\mathcal{Y}_j$ represented by an accumulator data structure $Y_j$ is the sum of all input that can be expressed using bits with values $2^e, e \in (a_j, b_j]$. Specifically, $Y_j = \sum\limits_{k = 0}^{n - 1}d(x_k, a_j, b_j)$ where

    $d(x, a, b) = \begin{cases}\roundtonearestinfty(x - \roundtonearestinfty(x, 2 \times 2^b), 2 \times 2^a) \text{ if } |x| \geq 2^b \\ \roundtonearestinfty(x, 2 \times 2^a) \text{ if } 2^b > |x| \geq 2^a \\ 0 \text{ if } 2^a > |x| \end{cases}$

    For ease of computation, accumulator ranges are chosen to be precomputed, fixed width intervals starting at $e_{\max}$. The possible bins

    $(a_0, b_0],$

    $(a_1, b_1],$

    $\vdots$

    for an indexed type of \textbf{width} $W$ are

    $(e_{\max} + 1 - W, e_{\max} + 1],$

    $(e_{\max} + 1 - 2\times W, e_{\max} + 1 - W],$

    $\vdots$

    $(e_{\min} - p + 1 + (e_{\max} - e_{\min} + p \mod W),$

    \indent \indent $e_{\min} - p + 1 + W + (e_{\max} - e_{\min} + p \mod W)]$.

    Section \ref{sec:underflow} explains why input in the bin

    $(e_{\min} - p, e_{\min} - p + 1 + (e_{\max} - e_{\min} + p \mod W)]$

    is not accumulated.

    As discussed in \cite{repsum}, $W < p - 2$. As discussed in section \ref{sec:overflow}, $2\times W > p + 1$.

    The accumulators in an indexed type correspond to contiguous bins in decreasing order. The \textbf{index} of $Y$ is the smallest $I \in \Z$ such that $2^{b_I + 1} > \max(|x_0|, ..., |x_n|)$ (equivalently, the smallest $I \in \Z$ such that $b_I \geq \max{e_0, ..., e_n}$). If $Y$ has index $I$, then $Y_j, j \in \{0, ..., fold - 1\}$ accumulates numbers in the bin $(a_{I + j}, b_{I + j}]$.

  \subsection{Implementation}
    \subsubsection{Data Types}
      As discussed in \cite{repsum}, indexed types are represented using floating point numbers to minimize traffic between floating point and integer arithmetic units. If an indexed type is used to sum \verb|double|, then it is composed entirely of \verb|double| and likewise for \verb|float|. ReproBLAS supports complex types as pairs of real and imaginary components (stored contiguously in memory). If an indexed type is used to sum complex \verb|double| or \verb|float|, then it is composed of pairs of real and imaginary \verb|double| or \verb|float| respectively. The decision to keep the real and imaginary components together (as opposed to keeping separate indexed types for real and imaginary parts of the sum) was motivated by a desire to process accumulators simultaneously with vectorized (SIMD, single instruction multiple data) instructions.

    \subsubsection{Primary and Carry}
      An indexed type's accumulators are each implemented using two underlying floating point fields. The \textbf{primary} field is used during accumulation, while the \textbf{carry} field holds overflow from the primary field. We denote the primary field and carry field of the accumulator $Y_j$ by ${Y_j}_S$ and ${Y_j}_C$. Because primary fields are frequently accessed sequentially, the primary fields and carry fields are each stored contiguously in separate arrays.

      The value ${\mathcal{Y}_j}_S$ is stored in the primary field ${Y_j}_S$ as an offset from $1.5\times \epsilon^{-1} \times 2^{a_{I + j}}$. This greatly simplifies the process of extracting the components of the input belonging in bin $(a_{I + j}, b_{I + j}]$.
      The value ${\mathcal{Y}_j}_S$ stored in the primary field ${Y_j}_S$ is expressed in Equation \ref{eq:pri}
      \begin{eq} The value ${\mathcal{Y}_j}_S$ stored in the primary field ${Y_j}_S$ of an indexed type $Y$ of index $I$

        ${\mathcal{Y}_j}_S = {Y_j}_S - 1.5\times\epsilon^{-1}\times2^{a_{I + j}}$
        \label{eq:pri}
      \end{eq}
      As discussed in \cite{repsum}, if we store each primary value ${\mathcal{Y}_j}_S$ as an offset from $1.5 \times \epsilon^{-1} \times 2^{a_{I + j}}$ and keep ${Y_j}_S$ within the range $(\epsilon^{-1} \times 2^{a_{I + j}}, 2 \times \epsilon^{-1} \times 2^{a_{I + j}})$, Algorithm \ref{alg:deposit} extracts the components of $x$ belonging to bins $(a_I, b_I], ..., (a_{I + fold - 1}, b_{I + fold - 1}]$ and adds them to ${Y_0}_S, ..., {Y_{fold - 1}}_S$ without error (and hence reproducibly) for all $x \in \F, |x| < 2^{b_I}$.
      \begin{alg}
        Extract components of floating point $x \in \F, |x| < 2^{b_I}$ in bins $(a_I, b_I], ..., (a_{I + fold - 1}, b_{I + fold - 1}]$ and add to indexed $Y$. Here, $(r | 1)$ represents the result of setting the last bit of the mantissa ($m_{p - 1}$) of floating-point $r$ to 1.
        \begin{algorithmic}
          \Function{Deposit}{fold, x, Y}
            \State $r \gets x$
            \For{$j = 0 \to (fold - 2)$}
              \State $M \gets {Y_j}_S + (r | 1)$
              \State $q \gets M - {Y_j}_S$
              \State ${Y_j}_S \gets M$
              \State $r \gets r - q$
            \EndFor
            \State ${Y_{fold - 1}}_S \gets {Y_{fold - 1}}_S + (r | 1)$
          \EndFunction
        \end{algorithmic}
        \label{alg:deposit}
      \end{alg}
      The last bit of $r$ is set to break ties when rounding "to nearest even" such that the amount accumulated does not depend on the size of ${Y_I}_S$ so far and the same amount ($d(x, a_{I + j}, b_{I + j})$) is always correctly deposited in each of $Y$'s primary fields assuming the value in each field satisfies previously specified constraints. Because $d(x, a_{I + j}, b_{I + j}) = 0$ for bins that are larger than the input, the top $fold$ accumulators can be computed reproducibly by computing the values in the top $fold$ accumulators needed for the largest $x$ seen so far and shifting them upwards (towards index $0$) as necessary. \cite{repsum} contains further discussions of the reproducibility of the algorithm.
      It is worth noting here that due to Corollary $3$ in \cite{repsum}, $|r| \leq 2^{b_{I + j}}$ when adding $(r | 1)$ to ${Y_j}_S$.

      In order to keep the primary fields in the necessary range during a deposit operation and to keep the representation of $Y_j$ unique, ${Y_j}_S$ is routinely renormalized to the range $[1.5 \times\epsilon^{-1} \times 2^{a_{I + j}}, 1.75 \times\epsilon^{-1} \times 2^{a_{I + j}})$.
      To renormalize, ${Y_j}_S$ is adjusted by $0.25 \times\epsilon^{-1} \times 2^{a_{I + j}}$ when necessary, leaving the carry field ${Y_j}_C$ to record the number of such adjustments.
      The value ${\mathcal{Y}_j}_C$ stored in the carry field ${Y_j}_C$ is expressed in Equation \ref{eq:car}
      \begin{eq} The value ${\mathcal{Y}_j}_C$ stored in the carry field ${Y_j}_C$ of an indexed type $Y$ of index $I$

        ${\mathcal{Y}_j}_C = {Y_j}_C \times 0.25\times\epsilon^{-1}\times2^{a_{I + j}}$
        \label{eq:car}
      \end{eq}
      The value $\mathcal{Y}_j$ stored in the accumulator $Y_j$ is expressed in Equation \ref{eq:acc}
      \begin{eq} The value $\mathcal{Y}_j$ stored in the accumulator $Y_j$ of an indexed type $Y$ of index $I$

        $\mathcal{Y}_j = {\mathcal{Y}_j}_S + {\mathcal{Y}_j}_C = ({Y_j}_S - 1.5 \times\epsilon^{-1}\times 2^{a_{I + j}}) + {Y_j}_C \times 0.25\times\epsilon^{-1}\times2^{a_{I + j}}$
        \label{eq:acc}
      \end{eq}
      Therefore the value $\mathcal{Y}$ represented by an indexed type $Y$ of index $I$ and fold $fold$ (the sum of $Y$'s accumulators) can be expressed as in Equation \ref{eq:indexedvalue}.
      \begin{eq} The real value $y \in \R$ of an indexed type $Y$ of index $I$

        $y = \sum\limits_{j = 0}^{fold - 1} \mathcal{Y}_j = \sum\limits_{j = 0}^{fold - 1} ({Y_j}_S - 1.5 \times\epsilon^{-1}\times 2^{a_{I + j}}) + {Y_j}_C \times 0.25\times\epsilon^{-1}\times2^{a_{I + j}}$
        \label{eq:indexedvalue}
      \end{eq}
      It is worth noting here that because the primary field ${Y_0}_S$ is stored with an exponent of $a_I + p$, it is unnecessary to store the index of an indexed type explicitly. The index can be determined by simply examining the exponent of ${Y_0}_S$, as all $a_I$ are distinct and the mapping between the exponent of ${Y_0}_S$ and the index of $Y$ is bijective.

    \subsubsection{Overflow}
      \label{sec:overflow}
      If an indexed type $Y$ has index 0 and the width is $W$, then the value in the primary field ${Y_0}_S$ is stored as an offset from $1.5\times\epsilon^{-1}\times2^{e_{\max} + 1 - W}$. However, $1.5\times\epsilon^{-1}\times2^{e_{\max} + 1 - W} = 1.5 \times 2^{e_{\max} + 1 + (p - W)} > 2 \times 2^{e_{\max}}$ since $W < p - 2$ \cite{repsum}, so it is out of the range of the floating-point system and not representable. Before discussing the solution to this overflow problem, take note of Theorem \ref{thm:overflow}.
      \begin{thm}
        If $2\times W > p + 1$, then for any indexed type $Y$ of index $I$ and any ${Y_j}_S$ such that $I + j \geq 1$, $|{Y_j}_S| < 2^{e_{\max}}$.

        $a_1 = e_{\max} + 1 - 2\times W$ by definition, therefore $a_1 < e_{\max} - p$ and since all quantities are integers, $a_1 \leq e_{\max} - p - 1$. As $a_0, a_1, ...$ is a positive decreasing sequence, $a_{I + j} \leq e_{\max} - p - 1$ since $I + j \geq 1$.

        ${Y_j}_S$ is kept within the range $(\epsilon^{-1} \times 2^{a_{I + j}}, 2 \times \epsilon^{-1} \times 2^{a_{I + j}})$, therefore
        $|{Y_j}_S| < 2 \times \epsilon^{-1} \times 2^{a_{I + j}} \leq 2^{1 + p} \times 2^{e_{\max} - 1 - p} = 2^{e_{\max}}$.

        \label{thm:overflow}
      \end{thm}
      By Theorem \ref{thm:overflow}, if $2\times W > p + 1$ then the only primary field that could possibly be in overflow is a primary field corresponding to bin 0, and all other primary fields have exponent less than $e_{\max}$. Therefore, we impose $2\times W > p + 1$ and express the value of the primary field corresponding to bin 0 as a scaled offset from $1.5\times2^{e_{\max}}$. Note that this preserves uniqueness of the exponent of the primary field corresponding to bin 0 because no other primary field has an exponent of $e_{\max}$. The value ${\mathcal{Y}_0}_S$ stored in the primary field ${Y_0}_S$ is expressed in Equation \ref{eq:pri0}.
      \begin{eq} The value ${\mathcal{Y}_0}_S$ stored in the primary field ${Y_0}_S$ of an indexed type $Y$ of index 0.

        ${\mathcal{Y}_0}_S = 2^{p - W + 1}\times({Y_0}_S - 1.5\times2^{e_{\max}})$
        \label{eq:pri0}
      \end{eq}
      Of course, what remains to be seen is how we can extract and add (as in Algorithm \ref{alg:deposit}) the components of a floating point number to an indexed type $Y$ of index 0. Algorithm \ref{alg:deposit0} shows the adaptation of Algorithm $\ref{alg:deposit}$ for types of index 0. Note that all of the same assumptions must hold from \ref{alg:deposit} except that ${Y_0}_S$ must now be kept within the range $(2^{e_{\max}}, 2 \times 2^{e_{\max}})$.
      \begin{alg}
        Extract components of floating point $x$ in bins $(a_0, b_0], ..., (a_{fold - 1}, b_{fold - 1}]$ and add to indexed $Y$ of index 0. Here, $(r | 1)$ represents the result of setting the last bit of the mantissa ($m_{p - 1}$) of floating-point $r$ to 1.
        \begin{algorithmic}
          \Function{Deposit0}{fold, x, Y}
            \State $r \gets x / 2^{p - W + 1}$
            \State $M \gets {Y_0}_S + (r | 1)$
            \State $q \gets M - {Y_0}_S$
            \State ${Y_0}_S \gets M$
            \State $q \gets q \times 2^{p - W + 1}$
            \State $r \gets x - q$
            \For{$j = 1 \to (fold - 2)$}
              \State $M \gets {Y_j}_S + (r | 1)$
              \State $q \gets M - {Y_j}_S$
              \State ${Y_j}_S \gets M$
              \State $r \gets r - q$
            \EndFor
            \State ${Y_{fold - 1}}_S \gets {Y_{fold - 1}}_S + (r | 1)$
          \EndFunction
        \end{algorithmic}
        \label{alg:deposit0}
      \end{alg}

      Algorithm \ref{alg:deposit0} has a few key features worth pointing out. First, since $|x| < 2^{e_{\max} + 1}$, then the value of $r$ after it's first assignment satisfies $|r| < 2^{e_{\max} - p + W + 1}$. This shows both that the extraction of the top bin will work correctly and that the top bin is the largest bin necessary to deposit any finite $x \in \F$.
      Furthermore, since $x$ is scaled by a factor of two, the significand of $r$ is equal to that of $x$.
      Therefore, the component of $r$ belonging to the bin $(e_{\max} - p, e_{\max} - p + W]$ is equivalent to the component of $x$ belonging to the bin $(e_{\max} + 1 - W, e_{\max} + 1]$ scaled by $2^{p - W + 1}$. This component of $r$ is extracted, stored in q, and added to ${Y_0}_S$. We can therefore scale this component by $2^{p - W + 1}$ to obtain the component of $x$ belonging to the bin $(e_{\max} + 1 - W, e_{\max} + 1]$. As $x$ is representable, so is this component. We can then subtract this component from $x$ and continue as in Algorithm \ref{alg:deposit}.

      Notice that after the first extraction, we cannot simply subtract $q$ from $r$ and then scale $r$ up and continue, as there may have been underflow when scaling $x$ down. We must scale $q$ up and subtract it from the original $x$.

    \subsubsection{Underflow}
      \label{sec:underflow}
      Here we consider the effects of underflow on algorithms described in \cite{repsum} and how they can be avoided. In Algorithm \ref{alg:deposit}, when the last bit of $r$ is set to 1, it is assumed that this last bit will only serve to fix the direction of the rounding mode. However, if ${Y_j}_S$ is denormal, that last bit may very well be accumulated!

      For Algorithm \ref{alg:deposit} to work correctly when adding $r | 1$ to ${Y_j}_S$, $\ulp(r)$ must be less than half of the rounding error when adding a number to ${Y_j}_S$. Mathematically, $\ulp(r) < \ulp({Y_j}_S)/2$.
      If $r$ is a normalized number, then because $|r| \leq 2^{b_{I + j}} = \ufp({Y_j}_S)/2^{p - W}$, and $W < p - 2$, we have $\ulp(r) < \ulp({Y_j}_S)/2$. Therefore, it is only possible for $\ulp(r) \geq \ulp({Y_j}_S)/2$ if $r$ is denormalized.

      The unit in the last place of a denormalized number is always equal to $2^{e_{\min} - p + 1}$. Therefore, $\ulp(r) < \ulp({Y_j}_S)/2$ implies $e_{\min} - p + 1 < a$. The smallest bin is

      $(e_{\min} - p + 1 + (e_{\max} - e_{\min} + p \mod W),$

      \indent \indent $e_{\min} - p + 1 + W + (e_{\max} - e_{\min} + p \mod W)]$.

      and since

      $e_{\min} - p + 1 + (e_{\max} - e_{\min} + p \mod W) > e_{\min} - p + 1$,

      deposits on the smallest bin and all larger bins satisfy $\ulp(r) < \ulp({Y_j}_S)/2$ and are exact.

      Since $W < p - 2$,

      $e_{\min} - p + 1 + (e_{\max} - e_{\min} + p \mod W) < e_{\min} - 1$.

      Therefore, all input in the bin $(e_{\min} - 1, e_{\max} + 1]$ is deposited.

      There are several ways to deposit the input in the denormal range. One simple way the algorithm could be extended to denormal inputs would be to scale the bottom bins up, as was done to handle overflow. Due to the relatively low priority for accumulating denormal values, these methods were not implemented.

    \subsubsection{Exceptions}
      Indexed types are capable of representing exceptional cases such as \verb|NaN| (Not a Number) and \verb|Inf| (Infinity). An indexed type $Y$ stores it's exception status in it's first primary field ${Y_0}_S$.

      A value of $0$ in ${Y_0}_S$ indicates that nothing has been added to ${Y_0}_S$ yet. The smallest bin is

      $(e_{\min} - p + 1 + (e_{\max} - e_{\min} + p \mod W),$

      \indent \indent $e_{\min} - p + 1 + W + (e_{\max} - e_{\min} + p \mod W)]$

      and since the ${Y_j}_S$ are kept within the range $(\epsilon^{-1} \times 2^{a_{I + j}}, 2 \times \epsilon^{-1} \times 2^{a_{I + j}})$ (where $I$ is the index), the smallest possible ${Y_j}_S$ is

      $\epsilon^{-1} \times 2^{e_{\min} - p + 1 + (e_{\max} - e_{\min} + p \mod W)} > 2^{e_{\min} + 1}$.

      Therefore $0$ is previously unused in other contexts and is a valid sentinel value. (As the exponent of $0$ is distinct from the exponent of normalized values, the bijection between the index of an indexed type $Y$ and the exponent of ${Y_0}_S$ is preserved)

      A value of \verb|Inf| or \verb|-Inf| in ${Y_0}_S$ indicates that one or more \verb|Inf| or \verb|-Inf| (and no other exceptional values) have been added to $Y$ respectively.

      A value of \verb|NaN| in ${Y_0}_S$ indicates that one or more \verb|NaN| have been added to $Y$ or one or more of both \verb|Inf| and \verb|-Inf| have been added to $Y$.

      As the ${Y_j}_S$ are kept finite to store finite values, \verb|Inf|, \verb|-Inf|, and \verb|NaN| are previously unused in other contexts and are valid sentinel values. (As the exponent of \verb|Inf|, \verb|-Inf|, and \verb|NaN| is distinct from the exponent of finite values, the bijection between the index of an indexed type $Y$ and the exponent of ${Y_0}_S$ is preserved)

      This behavior follows the behavior for exceptional values in IEEE 754-2008 floating point arithmetic and is therefore easy to implement. At the beginning of \ref{alg:deposit}, we may simply check $x$ and ${Y_0}_S$ for the exceptional values \verb|Inf|, \verb|-Inf|, and \verb|NaN|. If any one of $x$ or ${Y_0}_S$ is indeed exceptional, we add $x$ to the (possibly finite) ${Y_0}_S$. Otherwise, we deposit the finite value normally.

      As \verb|Inf|, \verb|-Inf|, and \verb|NaN| add associatively, this behavior is reproducible.

      It should be noted here that it is very much possible to achieve a final result of \verb|Inf| or \verb|-Inf| when ${Y_0}_S$ is finite. This is due to the fact that the indexed representation can express values outside of the range of the floating point numbers that it is composed with. More specifically, it is very much possible for the value $y$ represented by the indexed type $Y$ to satisfy $|y| \geq 2 \times 2^{e_{\max}}$.

\section{Basic Operations}
  \subsection{Update}
    As noted in Algorithm \ref{alg:deposit}, when adding $x \in \F$ to an indexed type $Y$ of index $I$ and fold $fold$, we make the assumption that $|x| < 2^{b_I}$. However, this is not always the case and sometimes it is necessary to adjust the index of $Y$. This adjustment is called an \textbf{update}. The process of updating $Y$ to have index $J > I$ is summarized succinctly in Algorithm \ref{alg:update}.
    \begin{alg}
      Update indexed $Y$ of index $I$ and fold $fold$ to have an index suitable to deposit $x$ where the bin $(a_{J}, b_{J}]$ satisfies $2^{b_{J}} > |x| \geq 2^{a_{J}}$.
      \begin{algorithmic}
        \Function{Update}{fold, x, Y}
          \If{$J < I$}
            \State $[{Y_{\min(I - J, fold)}}_S, ..., {Y_{fold - 1}}_S] \gets [{Y_0}_S, ..., {Y_{fold - 1 - \min(I - J, fold)}}_S]$
            \State $[{Y_0}_S, ..., {Y_{\min(I - J, fold) - 1}}_S] \gets [1.5 \times \epsilon^{-1} \times a_{J}, ..., 1.5 \times \epsilon^{-1} \times a_{\min(I, fold + J) - 1}]$
            \State $[{Y_{\min(I - J, fold)}}_C, ..., {Y_{fold - 1}}_C] \gets [{Y_0}_C, ..., {Y_{fold - 1 - \min(I - J, fold)}}_C]$
            \State $[{Y_0}_C, ..., {Y_{\min(I - J, fold) - 1}}_C] \gets [0, ..., 0]$
          \EndIf
        \EndFunction
      \end{algorithmic}
      \label{alg:update}
    \end{alg}
    The update operation is described in the update section of Algorithm $6$ in \cite{repsum}.

    It should be noted that if ${Y_0}_S$ is 0, then the update is performed as if $I + fold < J$. If ${Y_0}_S$ is \verb|Inf|, \verb|-Inf|, or \verb|NaN|, then $Y$ is not modified by an update.

    To speed up this operation, the factors $1.5 \times \epsilon^{-1} \times a_k$ for all valid $k \in Z$ are stored in a precomputed array.

  \subsection{Deposit}
    The deposit operation (here referred to as Algorithm \ref{alg:deposit}, a special case where $fold = 3$ is described in the extract $K$ first bins section of Algorithm $6$ in \cite{repsum}) lies firmly at the heart of ReproBLAS.

    The indexed type $Y$ that results from depositing the floating point values $x_0, ..., x_{n - 1}$ into an empty indexed type is referred to as the \textbf{indexed sum} of $x_0, ..., x_{n - 1}$

  \subsection{Renormalize}
    \label{sec:renormalize}
    When depositing values into an indexed type $Y$ of index $I$, the assumption is made that ${Y_j}_S \in (\epsilon^{-1}\times 2^{a_{I + j}}, 2 \times \epsilon^{-1}\times 2^{a_{I + j}})$ throughout the routine. To enforce this condition, the indexed type must be renormalized every $2^{p - w - 2}$ deposit operations. The renormalization procedure is shown in Algorithm \ref{alg:renorm}.
    \begin{alg}
      For an indexed $Y$ with index $I$, assuming ${Y_j}_S \in [1.25 \times \epsilon^{-1}\times 2^{a_{I + j}}, 2 \times \epsilon^{-1}\times 2^{a_{I + j}})$, renormalize $Y$ such that ${Y_j}_S \in [1.5 \times \epsilon^{-1}\times 2^{a_{I + j}}, 1.75 \times \epsilon^{-1}\times 2^{a_{I + j}})$.
      \begin{algorithmic}
        \Function{Renorm}{fold, Y}
          \For{$j \in 0 \to fold - 1$}
            \If{${Y_j}_S < 1.5 \times \ufp({Y_j}_S)$}
              \State ${Y_j}_S \gets {Y_j}_S + 0.25 \times \ufp({Y_j}_S)$
              \State ${Y_j}_C \gets {Y_j}_C - 1$
            \EndIf
            \If{${Y_j}_S \geq 1.75 \times \ufp({Y_j}_S)$}
              \State ${Y_j}_S \gets {Y_j}_S - 0.25 \times \ufp({Y_j}_S)$
              \State ${Y_j}_C \gets {Y_j}_C + 1$
            \EndIf
          \EndFor
        \EndFunction
      \end{algorithmic}
      \label{alg:renorm}
    \end{alg}
    The renormalization operation is described in the carry-bit propagation section of Algorithm $6$ in \cite{repsum}, although it has been slightly modified so as not to include an extraneous case.

    To show the reasoning behind the assumptions in Algorithm \ref{alg:renorm}, consider the case in which floating point $x_0, x_1, ...$ are successively deposited in an indexed type $Y$ which satisfies ${Y_j}_S \in [1.5 \times \epsilon^{-1}\times 2^{a_{I + j}}, 1.75 \times \epsilon^{-1}\times 2^{a_{I + j}})$. (Such a condition is satisfied upon initialization of an empty $Y$)

    First, note that $|d(x_k, a_{I + j}, b_{I + j})| \leq 2^{b_{I + j}}$, where $d(x_k, a_{I + j}, b_{I + j})$ is the amount added to ${Y_j}_S$ on iteration $j$. This is due to the definition of $d(x_k, a_{I+j}, b_{I + j})$ or to Corollary 3 of \cite{repsum}.

    As the deposit operation extracts and adds the appropriate component of $x_k$ exactly (assuming ${Y_j}_S$ lies within the appropriate boundaries at each step, which will be shown),

    Therefore,

    $|\sum \limits_{n = 0}^{k - 1} d(x_k, a_{I + j}, b_{I + j})| \leq n \times 2^{b_{I + j}} = n \times 2^{W} \times 2^{a_{I + j}}$

    and if $n <= 2^{p - W - 2}$, then after the $n^{th}$ deposit

    ${Y_j}_S \in [(1.5 \times \epsilon^{-1} - n \times 2^W)\times 2^{a_{I + j}}, (1.75 \times \epsilon^{-1} + n \times 2^W)\times 2^{a_{I + j}})$

    \indent\indent$\in [1.25 \times \epsilon^{-1}\times 2^{a_{I + j}}, 2 \times \epsilon^{-1}\times 2^{a_{I + j}})$

    Therefore, after another renormalization, the primary fields would once again satisfy

    ${Y_j}_S \in [1.5 \times \epsilon^{-1}\times 2^{a_{I + j}}, 1.75 \times \epsilon^{-1}\times 2^{a_{I + j}})$

  \subsection{Reduce}
    An operation to produce the sum of two indexed types is necessary to perform a reduction. For completeness we include the algorithm here, although apart from the renormalization step, it is equivalent to Algorithm $7$ in \cite{repsum}.
    \begin{alg}
      For an indexed type $Y$ (the indexed sum of some $x_0, ..., x_{n - 1} \in \F$) with index $I$ and indexed type $Z$ with index $J$ (the indexed sum of some $x_n, ..., x_{n + m - 1} \in \F$), add $Z$ to $Y$. That is, set $Y$ to the indexed sum of $x_0, ..., x_{n + m - 1}$. At the start and end of the algorithm, we may assume

${Y_j}_S \in [1.5 \times \epsilon^{-1}\times 2^{a_{I + j}}, 1.75 \times \epsilon^{-1}\times 2^{a_{I + j}})$ and

${Z_j}_S \in [1.5 \times \epsilon^{-1}\times 2^{a_{J + j}}, 1.75 \times \epsilon^{-1}\times 2^{a_{J + j}}).$
      \begin{algorithmic}
        \Function{Reduce}{fold, Y, Z}
          \If{$J > I$}
            \State $R \gets Z$
            \State \Call{Reduce}{fold, $R$, $Y$}
            \State $Y \gets R$
          \EndIf
          \For{$j \in 0 \to J$}
            \State ${Y_{j + I - J}}_S \gets {Y_{j + I - J}}_S + {Z_j}_S - 1.5 \times \epsilon^{-1} \times 2^{a_{I + j}}$
            \State ${Y_{j + I - J}}_C \gets {Y_{j + I - J}}_C + {Z_j}_C$
          \EndFor
          \State \Call{Renorm}{fold, $Y$}
        \EndFunction
      \end{algorithmic}
      \label{alg:reduce}
    \end{alg}

  \subsection{Convert}
    \label{sec:convert}
    It is necessary to provide the ability to convert between indexed and floating point representations of a number.

    Converting a floating point number to an indexed type should produce, for transparency and reproducibility, an indexed type equivalent to the indexed sum of the floating point number.
    The procedure is very simply summarized by Algorithm \ref{alg:conv2indexed}
    \begin{alg}
      Convert floating point $x$ to indeed $Y$ with fold $fold$.
      \begin{algorithmic}
        \Function{ConvertFloatToIndexed}{fold, x, Y}
          \State $Y \gets 0$
          \State \Call{Update}{fold, x, Y}
          \State \Call{Deposit}{fold, x, Y}
          \State \Call{Renorm}{fold, Y}
        \EndFunction
      \end{algorithmic}
      \label{alg:conv2indexed}
    \end{alg}

    Converting an indexed type to a floating point number is more difficult. However, because \cite{repsum} guarantees that all fields in the indexed type are reproducible, as long as the fields are operated upon deterministically, any method to evaluate Equation \ref{eq:indexedvalue} accurately and without unnecessary overflow is suitable. Following the methods in \cite{sortsum}, we add the floating point numbers in order of decreasing unnormalized exponent using a higher intermediate precision. As discussed in $\cite{sortsum}$, the intermediate precision must be greater than $p + \ceil{\log_2(2 \times fold)}$ as there are $2 \times fold$ elements to be summed.

    When adding the fields it is not necessary to examine the values in the fields or sort them explicitly. Their unnormalized exponent does not depend on their values, and their unnormalized exponents have a predetermined order.

    Consider indexed $Y$ of index $I$ and fold $fold$.
    As each value ${\mathcal{Y}_j}_S$ in a primary field ${Y_j}_S$ is an offset from $1.5 \times \epsilon^{-1} \times 2^{a_{I + j}}$ and ${Y_j}_S \in (\epsilon^{-1} \times 2^{a_{I + j}}, 2 \times \epsilon^{-1} \times 2^{a_{I + j}})$, ${\mathcal{Y}_j}_S$ can be expressed exactly using an unnormalized floating point number ${\mathcal{Y}'_P}_j$ with an exponent of $a_{I + j} + p - 1$.
    As each carry field ${Y_j}_C$ is a count of renormalization adjustments later scaled by $0.25 \times \epsilon^{-1} \times 2^{a_{I + j}}$, ${\mathcal{Y}_j}_C$ can be expressed exactly using an unnormalized floating point number ${\mathcal{Y}'_j}_C$ with an exponent of $a_{I + j} + p + p - 3$.

    For all $k < j$, $\exp({\mathcal{Y}'_k}_S) > \exp({\mathcal{Y}'_j}_S)$ and $\exp({\mathcal{Y}'_k}_C) > \exp({\mathcal{Y}'_j}_C)$ because $a_{I + k} > a_{I + j}$.

    Note that $\exp({\mathcal{Y}'_j}_C) = a_{I + j} + p + p - 3$

    and

    $\exp({\mathcal{Y}'_{j - 1}}_S) = a_{I + j - 1} + p - 1 = a_{I + j} + W + p - 1$.

    Therefore $\exp({\mathcal{Y}'_j}_C) > \exp({\mathcal{Y}'_{j - 1}}_S)$ using $W < p - 2$.

    Note that $\exp({\mathcal{Y}'_j}_C) = a_{I + j} + p + p - 3$

    and

    $\exp({\mathcal{Y}'_{j - 2}}_S) = a_{I + j - 1} + p - 1 = a_{I + j} + 2\times W + p - 1$.

    Therefore $\exp({\mathcal{Y}'_j}_C) < \exp({\mathcal{Y}'_{j - 2}}_S)$ using $2 \times W > p + 1$.

    Combining the above inequalities,

    \indent\indent $\exp({\mathcal{Y}'_0}_C)$

    \indent\indent $ > \exp({\mathcal{Y}'_1}_C)$

    \indent\indent $ > \exp({\mathcal{Y}'_0}_S)$

    \indent\indent $ > \exp({\mathcal{Y}'_2}_C)$

    \indent\indent $ > \exp({\mathcal{Y}'_1}_S)$

    \indent\indent $ \vdots$

    \indent\indent $ > \exp({\mathcal{Y}'_{fold - 2}}_C)$

    \indent\indent $ > \exp({\mathcal{Y}'_{fold - 3}}_S)$

    \indent\indent $ > \exp({\mathcal{Y}'_{fold - 1}}_C)$

    \indent\indent $ > \exp({\mathcal{Y}'_{fold - 2}}_S)$

    \indent\indent $ > \exp({\mathcal{Y}'_{fold - 1}}_S)$.

    These numbers may, for convenience of notation, be referred to in order as $\gamma'_0, ..., \gamma'_{2 \times fold - 1}$.
    $\gamma_k$ denotes the normalized representations of the $\gamma'_k$, and it should be noted that $\gamma_k = \gamma'_k$ as real numbers and that $\exp(\gamma_k) \leq \exp(\gamma'_k)$.

    It should be noted that the ${\mathcal{Y}'_j}_S$ and the ${\mathcal{Y}'_j}_C$ can be expressed exactly using floating point types of the same precision as ${Y_j}_S$ and ${Y_j}_C$ (except in the case of overflow, in which a scaled version may be obtained), and such exact floating point representations can be obtained using Equation \ref{eq:pri} and Equation \ref{eq:car}.

    Notice that $|\gamma'_0| = |{\mathcal{Y}'_0}_C| < 2 \times 2^{\exp({\mathcal{Y}'_0}_C)} = 2 \times 2^{e_{\max} + 1 - W + p + p - 3}$ and $\exp(\gamma'_0) > ... > \exp(\gamma'_{2 \times fold - 1})$.  Therefore $|\gamma'_k| \leq 2^{e_{\max} - W + p + p - 1 - k}$. The absolute value represented by an indexed type can therefore be bounded by

    $\sum\limits_{k = 0}^{2 \times fold - 1} |\gamma_k| < \sum\limits_{k = 0}^{2 \times fold - 1} 2^{e_{\max} - W + p + p - 1 - k} < \sum\limits_{k = 0}^{\infty} 2^{e_{\max} - W + p + p - 1 - k} = 2^{e_{\max} - W + p + p}$.

    If the intermediate precision has a maximum exponent greater than or equal to $e_{\max} - W + p + p - 1$, then no special cases to guard against overflow are needed.

    Algorithm \ref{alg:conv2float} represents a conversion routine in such a case.

    \begin{alg}
      Convert indexed $Y$ with index $I$ and fold $fold$ to floating point $x$. Here, $z$ is a floating point type with precision $P$ greater than $p + \ceil{\log_2(2 \times fold)}$ and maximum exponent $E_{\max}$ greater than $e_{\max} - W + p + p$
      \begin{algorithmic}
        \Function{ConvertIndexedToFloat}{fold, x, Y}
          \State $z \gets {\mathcal{Y}_0}_C$
          \For{$j \in 1 \to fold - 1$}
            \State $z \gets z + {\mathcal{Y}_j}_C$
            \State $z \gets z + {\mathcal{Y}_{j - 1}}_S$
          \EndFor
          \State $z \gets {\mathcal{Y}_{fold - 1}}_S$
          \State $x \gets z$
        \EndFunction
      \end{algorithmic}
      \label{alg:conv2float}
    \end{alg}

    If an intermediate type with exponent greater than ore equal to $e_{\max} - W + p + p - 1$ is not available, the $\gamma_k$ must be scaled down by some factor during addition and the sum scaled back up when subsequent additions can no longer effect an overflow situation.

    If the sum is to overflow, it will overflow regardless of the values of any ${\mathcal{Y}_j}_S$ or ${\mathcal{Y}_j}_C$ with $|{\mathcal{Y}_j}_S| < 0.5 \times 2^{-P} \times 2^{e_{\max}}$ or $|{\mathcal{Y}_j}_C| < 0.5 \times 2^{-P} \times 2^{e_{\max}}$. If the floating point sum of precision $P$ has exponent greater than or equal to $e_{\max}$ these numbers are not large enough to have any effect when added to the sum. If the sum has exponent less than $e_{\max}$, then additions of these numbers cannot cause the exponent of the sum to exceed $e_{\max}$ for similar reasons.

    As the maximum absolute value of the true sum is strictly smaller than $2^{e_{\max} - W + p + p}$, a sufficient scaling factor is $2^{p + p - W - 2}$, meaning that the maximum absolute value of the true scaled sum is strictly smaller $2 \times 2^{e_{\max} - 1}$ (and since it will be shown later that the computed sum is accurate to within a small factor of the true sum, the computed sum will stay strictly smaller than $2 \times 2^{e_{\max}}$ and will not overflow.)

  When $\exp(\gamma'_k) < e_{\max} - P - 1$, the sum may be scaled back up and the remaining numbers added without scaling. Notice that no overflow can occur during addition in this algorithm. If an overflow is to occur, it will happen only when scaling back up.

    If the sum is not going to overflow, then the smaller $y'_k$ must be added as unscaled numbers to avoid underflow.

    Algorithm \ref{alg:conv2floatoverflow} represents a conversion routine in such a case.

    \begin{alg}
      Convert indexed $Y$ with index $I$ and fold $fold$ to floating point $x$. Here, $z$ is a floating point type with precision $P$ greater than $p + \ceil{\log_2(2 \times fold)}$.
      \begin{algorithmic}
        \Function{ConvertIndexedToFloat}{fold, x, Y}
          \State $j \gets 1$
          \While{$j \leq 2 \times fold$ and $\exp(\gamma_j) \geq e_{\max} - P - 1$}
            \State $z \gets z + (\gamma_j / 2^{p + p - W - 2})$
            \State $j \gets j + 1$
          \EndWhile
          \State $z \gets z \times 2^{p + p - W - 2}$
          \While{$j \leq 2 \times fold$}
            \State $z \gets z + \gamma_j$
            \State $j \gets j + 1$
          \EndWhile
          \State $x \gets z$
        \EndFunction
      \end{algorithmic}
      \label{alg:conv2floatoverflow}
    \end{alg}

    If an indexed type is composed of \verb|float|, then \verb|double| provides sufficient precision and exponent to use as an intermediate type and Algorithm \ref{alg:conv2float} may be used to convert to a floating point number.
    However, if an indexed type is composed of \verb|double|, many machines may not have any higher precision available. To provide a conversion function that is identical across hardware, we use \verb|double-double| precision implemented in software to achieve sufficient intermediate precision \cite{doubledouble}. As this does not extend the exponent range we must use Algorithm \ref{alg:conv2floatoverflow} to convert to a floating point number.

  \subsection{Error Bound}
    Consider the indexed sum $Y$ of fold $fold$ of floating point numbers $x_0, ..., x_{n - 1}$. We denote the true sum $\sum \limits_{k = 0}^{n - 1} x_k$ by $T$, the true value of the indexed sum as obtained using Equation \ref{eq:indexedvalue} by $\mathcal{Y}$, and the floating point approximation of $\mathcal{Y}$ obtained using an appropriate algorithm from section \ref{sec:convert} by $\overline{\mathcal{Y}}$.

    \cite{repsum} discusses the absolute error $|T - \mathcal{Y}|$ but does not give a method to construct $\overline{\mathcal{Y}}$ and therefore no error bound ($|T - \overline{\mathcal{Y}}|$) on the final floating point answer was given. Here we extend the error bound of \cite{repsum} all the way to the final return value of the algorithm.

    Throughout this section we assume that all input falls within a bin and that $T$ and $\mathcal{Y}$ are larger than the largest denormalized floating point number.

    To show an error bound for the conversion routine, we first state Theorem \ref{thm:sortsum}

    \begin{thm}
      This theorem is a restatement of statement 1 of Theorem $1$ in \cite{sortsum}.

      Assume we have a floating point format of precision $p$ and an intermediate format of precision $P$. Assume that the following hold:
      \begin{enumerate}
        \item $p \geq 2$ (there are at least 2 bits of precision in the bins)
        \item $P \geq p + 1$ (the intermediate precision is larger than the original)
        \item the intermediate exponent range is at least as large as the original
        \item rounding is in "to nearest" mode (breaking ties arbitrarily)
        \item underflow is gradual
        \item no overflow occurs
      \end{enumerate}
      Then, if we sum at most $1 + \floor{\frac{2^{P - p}}{(1 - 2^{-p})}}$ unnormalized numbers in order of decreasing exponent using the intermediate precision, the error is less than $(\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times \ulp(T)$, where $T$ is the true sum.
      \label{thm:sortsum}
    \end{thm}

    It has been shown in \cite{repsum} that

    $|T - \mathcal{Y}| < n \times 2^{W \times (1 - fold) - 1} \times \max|x_k|$

    Because the intermediate precision $P$ used to sum the values stored in the various fields of $Y$ is assumed greater than $p + \ceil{\log_2(2 \times fold)}$, we sum at most $2^{P - p} < 1 + \floor{\frac{2^{P - p}}{1 - 2^{-p}}}$ values that may be considered as unnormalized values in order of decreasing unnormalized exponent (the same argument is made in the proof of Theorem 2 of \cite{sortsum}), and Theorem \ref{thm:sortsum} applies to yield

    $|\mathcal{Y} - \overline{\mathcal{Y}}| < (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times \ulp(\mathcal{Y})$.

    By the triangle inequality

    $|\mathcal{Y}| \leq |T| + |T - \mathcal{Y}| < |T| + n \times 2^{W \times (1 - fold) - 1} \times \max|x_k|$,

    and because $T$ is assumed to be in the normalized range,

    $\ulp(\mathcal{Y}) \leq \ulp(|T| + n \times 2^{W \times (1 - fold) - 1} \times \max|x_k|)$

    \indent \indent$\leq (|T| + n \times 2^{W \times (1 - fold) - 1} \times \max|x_k|) \times 2 \times \epsilon$.

    The above results can be used to obtain Equation \ref{eq:error}.

    \begin{eq} The absolute error of the floating point approximation of an indexed sum $|T - \overline{\mathcal{Y}}|$ is bounded by

      $|T - \overline{\mathcal{Y}}| \leq |T - \mathcal{Y}| + |\mathcal{Y} - \overline{\mathcal{Y}}|$

      \indent\indent$< n \times 2^{W \times (1 - fold) - 1} \times \max|x_k| + (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times \ulp(\mathcal{Y})$

      \indent\indent$< n \times 2^{W \times (1 - fold) - 1} \times \max|x_k| + $

      \indent\indent \indent$(\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times(|T| + n \times 2^{W \times (1 - fold) - 1} \times \max|x_k|) \times 2 \times \epsilon$

      \indent\indent$< n \times \max|x_k|\times 2^{W \times (1 - fold) - 1} \times(1 + (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2}) \times 2 \times \epsilon) + $

      \indent\indent \indent$(\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times |T| \times 2 \times \epsilon$
      \label{eq:error}
    \end{eq}

    Equation \ref{eq:error} can be approximated as Equation \ref{eq:errorapprox}.

    \begin{eq} The absolute error of the floating point approximation of an indexed sum $|T - \overline{\mathcal{Y}}|$ is approximately bounded by

      $|T - \overline{\mathcal{Y}}| < n \times \max|x_k|\times 2^{W \times (1 - fold) - 1} \times(1 + (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2}) \times 2 \times \epsilon) + $

      \indent \indent$(\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times |T| \times 2 \times \epsilon$

      \indent\indent$\approx n \times \max|x_k|\times 2^{W \times (1 - fold) - 1} + 3 \times \epsilon \times |T|$
      \label{eq:errorapprox}
    \end{eq}

    A perhaps more useful mathematical construction is the error expressed relative to the result $\overline{\mathcal{Y}}$, and not the theoretical sum $T$. Again by the triangle inequality,

    $|\mathcal{Y}| \leq |\overline{\mathcal{Y}}| + |\mathcal{Y} - \overline{\mathcal{Y}}|$.

    Applying the bound on $|\mathcal{Y} - \overline{\mathcal{Y}}|$ yields

    $|\mathcal{Y}| < |\overline{\mathcal{Y}}| + (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times \ulp(\mathcal{Y})$.

    and because $\mathcal{Y}$ is assumed to be in the normalized range,

    $|\mathcal{Y}| < |\overline{\mathcal{Y}}| + (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times|\mathcal{Y}|\times 2 \times \epsilon$.

    After simplification,

    $|\mathcal{Y}| < |\overline{\mathcal{Y}}|\times (1 - (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times 2 \times \epsilon)^{-1}$.

    Again because $\mathcal{Y}$ is assumed to be in the normalized range,

    $\ulp(\mathcal{Y}) \leq \ulp(|\overline{\mathcal{Y}}|\times (1 - (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times 2 \times \epsilon)^{-1})$

    \indent \indent$\leq |\overline{\mathcal{Y}}|\times (1 - (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times 2 \times \epsilon)^{-1} \times 2 \times \epsilon$.

    The above results can be used to obtain Equation \ref{eq:error2}.

    \begin{eq} The absolute error of the floating point approximation of an indexed sum $|T - \overline{\mathcal{Y}}|$ is bounded by

      $|T - \overline{\mathcal{Y}}| \leq |T - \mathcal{Y}| + |\mathcal{Y} - \overline{\mathcal{Y}}|$

      \indent\indent$< n \times 2^{W \times (1 - fold) - 1} \times \max|x_k| + (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times \ulp(\mathcal{Y})$

      \indent\indent$< n \times 2^{W \times (1 - fold) - 1} \times \max|x_k| + $

      \indent\indent \indent$(\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times|\overline{\mathcal{Y}}|\times (1 - (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times 2 \times \epsilon)^{-1} \times 2 \times \epsilon$
      \label{eq:error2}
    \end{eq}

    Equation \ref{eq:error2} can be approximated as Equation \ref{eq:error2approx}.

    \begin{eq} The absolute error of the floating point approximation of an indexed sum $|T - \overline{\mathcal{Y}}|$ is approximately bounded by

      $|T - \overline{\mathcal{Y}}| < n \times 2^{W \times (1 - fold) - 1} \times \max|x_k| + $

      \indent \indent$(\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times|\overline{\mathcal{Y}}|\times (1 - (\frac{1}{1 - 2^{1 - p}} + \frac{1}{2})\times 2 \times \epsilon)^{-1} \times 2 \times \epsilon$

      \indent\indent$\approx n \times \max|x_k|\times 2^{W \times (1 - fold) - 1} + 3 \times \epsilon \times |\overline{\mathcal{Y}}|$
      \label{eq:error2approx}
    \end{eq}

    We can compare Equation \ref{eq:errorapprox} to the error bound obtained if the accumulator fields were summed without extra precision. In this case, only the standard summation bound would apply and the absolute error would be bounded by

    $n \times \max|x_k|\times 2^{W \times (1 - fold) - 1} + (2 \times fold - 1) \times \epsilon \times \sum\limits_0^{2 \times fold - 1}\gamma_k$

    \indent\indent $= n \times \max|x_k|\times 2^{W \times (1 - fold) - 1} + (2 \times fold - 1) \times \epsilon \times |\mathcal{Y}|$

    \indent\indent$< n \times \max|x_k|\times 2^{W \times (1 - fold) - 1}$

    \indent\indent\indent$ + (2 \times fold - 1) \times \epsilon \times (|T| + n \times \max|x_k|\times 2^{W \times (1 - fold) - 1})$

    \indent\indent$= n \times \max|x_k|\times 2^{W \times (1 - fold) - 1}\times (1 + (2 \times fold - 1)\times \epsilon)$

    \indent\indent\indent$ + (2 \times fold - 1) \times \epsilon \times |T|$

    \indent\indent$\approx n \times \max|x_k|\times 2^{W \times (1 - fold) - 1}$

    \indent\indent\indent$ + (2 \times fold - 1) \times \epsilon \times |T|$

    Which is not as tight a bound as Equation $\ref{eq:errorapprox}$, and grows as the user tries to add more bins to increase accuracy.

  \subsection{Limits}
    \label{sec:limits}
    As discussed previously, the minimum fold accepted by ReproBLAS is 2. The maximum useful fold is $\floor{(e_{\max} - e_{\min} + p)/W}$, as this covers all of the bins.

    As discussed in \cite{repsum}, $W < p - 2$. As discussed in section \ref{sec:overflow}, $2\times W > p + 1$.

    ReproBLAS uses the values $W = 40$ for indexed \verb|double| and $W = 13$ for indexed \verb|float|. $W$ is available as the \verb|XIWIDTH| macro.

    As discussed in section \ref{sec:underflow}, only input corresponding to the bin $(e_{\min} - 1, e_{\max} + 1]$ is guaranteed to be accumulated.

    As absolute value of individual quantities added to ${Y_j}_S$ are not in excess of $2^{b_{I + j}}$, a maximum of $0.25\epsilon^{-1}2^{-W}$ elements may be deposited into ${Y_j}_S$ between renormalizations, as discussed in section \ref{sec:renormalize}. For indexed \verb|double| this number is $2^{11}$, whereas for indexed \verb|float| this number is $2^9$. This number is supplied programmatically using the \verb|XIENDURANCE| macro.

    As ${Y_j}_C$ must be able to record additions of absolute value 1 without error, ${Y_j}_C$ must stay in the range $(-\epsilon^{-1}, \epsilon^{-1})$. As each renormalization results in addition not in excess absolute value of 1 to ${Y_j}_C$, a maximum of $(\epsilon^{-1} - 1)$ renormalizations may be performed, meaning that an indexed sum represents the sum of a maximum of $0.25\epsilon^{-1}2^{-W} \times (\epsilon^{-1} - 1) \approx 2^{p + p - W - 2}$. For indexed \verb|double| this number is almost $2^64$, whereas for indexed \verb|float| this number is almost $2^33$. This number is supplied programmatically using the \verb|XICAPACITY| macro.

    The indexed types provided by ReproBLAS will, when used correctly, avoid intermediate overflow.

\section{Interface}
  \subsection{Fold}
  \subsection{Complex Types}
  \subsection{Naming Conventions}
  \subsection{Build System}
\section{indexed.h}
  \subsection{Overview}
  \subsection{Types}
  \subsection{Functions}
    \subsubsection{xixadd}
    \subsubsection{xixiadd}
    \subsubsection{xscale}
    \subsubsection{xixiaddsq}
\section{idxdBLAS.h}
  \subsection{Overview}
  \subsection{Functions}
    \subsubsection{xixdot}
    \subsubsection{xixnrm2}
    \subsubsection{xixgemv}
    \subsubsection{xixgemm}
  \subsection{Optimization}
    Due to the proportion of time spent in the deposit routine, optimization of the deposit routine was prioritized. In the event that multiple $x$ need to be added to $Y$, the deposit routine can be vectorized by accumulating the $x$ in multiple copies of $Y$. The number of copies of $Y$ to make, $c$, and the number of unrolled loop iterations, $u$ are tuning parameters.
\section{repBLAS.h}
\section{idxdMPI.h}
  \subsection{Types}
  \subsection{Functions}
    \subsubsection{XIXIREDUCE}
\section{Applications}
  \subsection{Parallel Reproducible Dot Product}
  \subsection{Parallel Reproducible Vector Norm}
  \subsection{Parallel Reproducible Matrix-Vector Multiply}
  \subsection{Parallel Reproducible Matrix-Matrix Multiply}
\begin{thebibliography}{9}
  \bibitem{repsum}
    Demmel, James, and Hong Diep Nguyen. Parallel Reproducible Summation. IEEE Transactions on Computers, 2014.
  \bibitem{ieee754}
    IEEE Standard for Floating-Point Arithmetic," IEEE Std 754-2008 , vol., no., pp.1,70, Aug. 29 2008
  \bibitem{c89}
    ANSI/ISO 9899-1990 American National Standard for Programming Languages - C, section 6.1.2.5
  \bibitem{sortsum}
    Demmel, James W., and Yozo Hida. Accurate floating point summation. Computer Science Division, University of California, 2002.
  \bibitem{doubledouble}
    Hida, Yozo, Xiaoye S. Li, and David H. Bailey. Quad-double arithmetic: Algorithms, implementation, and application. 15th IEEE Symposium on Computer Arithmetic, 2000.
\end{thebibliography}
\end{document}
