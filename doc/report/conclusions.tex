\section{Conclusions And Future Work}
  The algorithms we have presented have been shown to accurately sum binary IEEE 754-2008 floating point reproducibly. Reproducibility is independent of the ordering of data, blocking schemes, or reduction tree shape. The algorithms behave sensibly in overflow and underflow situations and work on exceptional cases such as \texttt{Inf}, \texttt{-Inf}, and \texttt{NaN}.

   We have specified all of the necessary steps to carry out reproducible summation in practice, including a conversion from the intermediate indexed type to a floating point result. We have also specified methods for reproducible absolute sums, dot products, norms, matrix-vector products, and matrix-matrix products. We have created an optimized library for reproducible summation, tested it, and shown that the performance is comparable to industry standards. We have included in our library methods for distributed memory reductions so that reproducible parallel routines may be built from our library.

   In the future, we plan to add PBLAS routines to our library so that users may benefit from reproducible parallel BLAS routines. We will extend the existing 

\begin{comment}

  With these considerations in mind, reproducible algorithms for summations were presented in \cite{repsum}. The algorithms were shown to enjoy the following properties:
  \begin{enumerate}
    \item They compute a reproducible sum independent of the order of the summands, how they are assigned to processors, or how they are aligned in memory.
    \item They make only basic assumptions about the underlying arithmetic (A subset of IEEE Standard 754-2008).
    \item They scale well as a performance-optimized, non-reproducible implementation, as $n$ (number of summands) and $p$ (number of processors) grow.
    \item The user can choose the desired accuracy of the result. In particular, getting a reproducible result with about the same accurace as the performance optimized algorithm is only be a small constant times slower, but higher accuracy is possible too.
  \end{enumerate}
  The algorithms of \cite{repsum} did not, however, work for all ranges of floating-point input nor did they contain all of the functional components necessary to be deployed in an existing application (they lacked an algorithm to convert from a reproducible type back to floating point format while maintaining accuracy). Our goal is to modify the algorithms in \cite{repsum} so that in addition to the above properties, they enjoy the following properties:
  \begin{enumerate}
    \item The algorithms can be applied in any binary IEEE 754-2008 floating point format, and any valid input in such a format can be summed using the algorithms. The algorithms must be able to sum numbers close to zero, numbers close to overflow, and exceptional values such as \texttt{NaN} and \texttt{Inf}, mimicking the behavior of IEEE floating point wherever possible.
    \item They must be expressed as basic operations that can be applied in several applications. They must be able to be built into a user-friendly, performant library.
  \end{enumerate}
\end{comment}
