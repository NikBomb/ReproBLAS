\section{The Indexed Type}
  \label{sec:indexed}
    The \textbf{indexed type} is used to represent the intermediate result of
    accumulation using Algorithms 6 and $7$ in \cite{repsum}.  An indexed type
    $Y$ is a data structure composed of several accumulator data structures
    $Y_0, ..., Y_{K - 1}$. An indexed type with $K$ accumulators is referred to
    as a \textbf{$K$-fold} indexed type. Due to their low accuracy, 1-fold
    indexed types are not considered.

    Let $Y$ be the indexed type corresponding to the reproducibly computed sum
    of $x_0, ..., x_{n - 1} \in \F$. $Y$ is referred to as the \textbf{indexed
    sum} of $x_0, ..., x_{n - 1}$, a term which will be defined formally in
    Section \ref{sec:indexed_sum}.

    Each accumulator $Y_k$ is a data structure used to accumulate the slices of
    input in the bin $(a_{I + k}, b_{I + k}]$ where $I$ is the \textbf{index}
    of $Y$ and $k \geq 0$. The \textbf{width} of an indexed
    type is equal to the width of its bins, $W$. Recall the assumptions
    \eqref{eq:wupper} and \eqref{eq:wlower} made on the value of $W$.

    The accumulators in an indexed type correspond to contiguous bins in
    decreasing order.     If $Y$ has index $I$, then $Y_k, k \in \{0, ..., K - 1\}$ accumulates slices
    of input in the bin $(a_{I + k}, b_{I + k}]$. If $I$ is so large that
    $I + K > i_{\max}$, then the extra $I + K - i_{\max}$ accumulators are unused.

    In ReproBLAS, the data type used to sum \texttt{double} is named \texttt{double\_indexed}, and likewise for \texttt{double complex}, \texttt{float}, and \texttt{float complex}. A $K$-fold indexed type can be allocated with the \texttt{idxd\_xialloc} method, and set to zero with the \texttt{idxd\_xisetzero} method. Both of these methods are defined in \texttt{idxd.h} (see Section \ref{sec:reproBLAS} for details).

    Section \ref{sec:indexed_primary_carry} elaborates on the specific fields
    that make up the indexed type and the values they represent. Sections
    \ref{sec:indexed_overflow}, \ref{sec:indexed_underflow_gradual},
    \ref{sec:indexed_underflow_abrupt}, and \ref{sec:indexed_exceptions}
    contain extensions of the indexed type to handle overflow, underflow, and
    exceptional values. Section \ref{sec:indexed_sum} explains how the indexed type can be used to represent the sum of several floating point numbers.

    \subsection{Primary and Carry}
      \label{sec:indexed_primary_carry}
      As discussed in \cite{repsum}, indexed types are represented using
      floating point numbers to minimize traffic between floating point and
      integer arithmetic units.

      In the ReproBLAS library, if an indexed type is used to sum
      \texttt{doubles}, then it is composed entirely of \texttt{doubles} and
      likewise for \texttt{floats}. ReproBLAS supports complex types as pairs
      of real and imaginary components (stored contiguously in memory). If an
      indexed type is used to sum complex \texttt{doubles} or \texttt{floats},
      then it is composed of pairs (real part, imaginary part) of
      \texttt{doubles} or \texttt{floats} respectively. The decision to keep
      the real and imaginary components together (as opposed to keeping
      separate indexed types for real and imaginary parts of the sum) was
      motivated by a desire to process accumulators simultaneously with
      vectorized (SIMD) instructions.

      The accumulators $Y_k$ of an indexed type $Y$ are each implemented using
      two underlying floating point fields. The \textbf{primary} field
      ${Y_k}_P$ is used during accumulation, while the \textbf{carry} field
      ${Y_k}_C$ holds overflow from the primary field. Because primary fields
      are frequently accessed sequentially, the primary fields and carry fields
      are each stored contiguously in separate arrays. The notation for the
      primary field ${Y_k}_P$ and carry field ${Y_k}_C$ corresponds to the
      ``$S_j$'' and ``$C_j$'' of Algorithm $6$ in \cite{repsum}.

      The numerical value ${\mathcal{Y}_k}_P$ represented by data stored in the
      primary field ${Y_k}_P$ is an offset from $1.5\epsilon^{-1}2^{a_{I + k}}$
      (corresponding to ``$M_{[i]}$'' at the beginning of Section IV.A. in
      \cite{repsum}), where $I$ is the index of $Y$, as shown in
      \eqref{eq:pri} below.
      Note that \eqref{eq:pri} only holds when $I+k > 0$. The special case of $I+k=0$,
      where $1.5\epsilon^{-1}2^{a_0} > 2^{1+e_{max}}$ is not representable,
      will be handled in Section~\ref{sec:indexed_overflow} below on Overflow.
      \begin{equation}
        {\mathcal{Y}_k}_P = {Y_k}_P - 1.5\epsilon^{-1}2^{a_{I + k}}
        \label{eq:pri}
      \end{equation}
      Representing the primary field value as an offset from $1.5\epsilon^{-1}2^{a_{I + k}}$ simplifies the process of extracting the slices of input in bins
      $(a_{I + k}, b_{I + k}]$. It will be shown in Theorem
      \ref{thm:ddepositrestricted} in Section~\ref{sec:primitiveops_deposit}
      that if we represent each primary value ${\mathcal{Y}_k}_P$ as in
      \eqref{eq:pri} and keep ${Y_k}_P$ within the range
      \(
      	(\epsilon^{-1} 2^{a_{I + k}}, 2 \epsilon^{-1} 2^{a_{I + k}}),
      \)
      then Algorithm
      \ref{alg:depositrestricted} in Section~\ref{sec:primitiveops_deposit}
      extracts the slices of $x$ in bins 
      \(
      	(a_I, b_I], \ldots, (a_{I + K - 1}, b_{I + K - 1}]
      \)
      and adds them to ${Y_0}_P, \ldots, {Y_{K - 1}}_P$ without error
      (and hence reproducibly) for all $x \in \F$, where $|x| < 2^{b_I}$.

      Because $d(x, I + k) = 0$ for bins with $|x| < 2^{a_{I + k}}$, the values
      in the greatest $K$ nonzero accumulators can be computed reproducibly by
      computing the values in the greatest $K$ accumulators needed for the
      largest $x$ seen so far. Upon encountering an $x \geq 2^{b_I}$, the
      accumulators can then be shifted towards index $0$ as necessary.  Since
      the maximum absolute value operation is always reproducible, so is the
      index of the greatest accumulator.
      %\cite{repsum} contains further discussions of the reproducibility of the algorithm.

      In order to keep the primary fields in the necessary range while the
      slices are accumulated and to keep the representation of $Y_k$ unique,
      ${Y_k}_P$ is routinely renormalized to the range 
      \(
        [1.5 \epsilon^{-1} 2^{a_{I + k}}, 1.75 \epsilon^{-1} 2^{a_{I + k}}).
      \)
      As will be shown in Section~\ref{sec:primitiveops_renormalize},
      that renormalization is required every $2^{p-W-2}$ iterations,
      so $2^{11}$ in double and $2^9$ in single precision.
      This means the renormalization introduces a very low overhead
      to the overall running time.
      %Section \ref{sec:primitiveops_renormalize} contains a discussion of how often such renormalizations are necessary.
      To renormalize, ${Y_k}_P$ is incremented or decremented by
      $0.25 \epsilon^{-1} 2^{a_{I + k}}$ as described in Algorithm~\ref{alg:renorm},
      leaving the carry field ${Y_k}_C$ to record the number of such adjustments.
      Depending on the data format used to store ${Y_k}_C$, the number of
      updates to one accumulator without overflow is limited,
      which determines the possible maximum number of inputs that can be
      reproducibly added to one accumulator.
      As will be explained in Section~\ref{sec:primitiveops_renormalize},
      Equation~\eqref{eq:totalfreq}, using the same precision $p$ as the primary field
      to store the carry field, the total number of inputs
      that can be reproducibly added to one accumulator is 
      $(\epsilon - 1)2^{p-W-2}$. This is approximately $2^{64}$ for 
      \texttt{double} and $2^{33}$ for \texttt{float}. See Section 
      \ref{sec:primitiveops_restrictions} for a summary of restrictions.
      The numerical value ${\mathcal{Y}_k}_C$ represented by data stored in the carry field
      ${Y_k}_C$ of an indexed type $Y$ of index $I$ is expressed in
      \eqref{eq:car}
      \begin{equation}
        {\mathcal{Y}_k}_C = (0.25\epsilon^{-1}2^{a_{I + k}}){Y_k}_C
        \label{eq:car}
      \end{equation}
      Combining \eqref{eq:pri} and \eqref{eq:car}, we get that the value $\mathcal{Y}_k$ of the accumulator $Y_k$ of an indexed type $Y$ of index $I$ is
      \begin{equation}
        \mathcal{Y}_k = {\mathcal{Y}_k}_P + {\mathcal{Y}_k}_C = ({Y_k}_P - 1.5 \epsilon^{-1}2^{a_{I + k}}) + (0.25\epsilon^{-1}2^{a_{I + k}}){Y_k}_C
        \label{eq:acc}
      \end{equation}
      Therefore, using  \eqref{eq:acc}, the numerical value $\mathcal{Y}$ represented by data stored in a $K$-fold indexed type $Y$ of index $I$ (the sum of $Y$'s accumulators) is
      \begin{equation}
        \mathcal{Y} = \sum\limits_{k = 0}^{K - 1} \mathcal{Y}_k = \sum\limits_{k = 0}^{K - 1} \bigl(({Y_k}_P - 1.5 \epsilon^{-1}2^{a_{I + k}}) + (0.25\epsilon^{-1}2^{a_{I + k}}){Y_k}_C\bigr)
        \label{eq:indexedvalue}
      \end{equation}
      It is worth noting that by keeping ${Y_k}_P$ within the range
      \(
      	(\epsilon^{-1} 2^{a_{I + k}}, 2 \epsilon^{-1} 2^{a_{I + k}})
      \)
      for $I+k > 0$, the exponent of ${Y_0}_P$ is $a_I + p$ when $I > 0$.
      The case of $I = 0$ will be explained in the below section of Overflow.
      Therefore it is unnecessary to store the index of an indexed type explicitly.
      As will be explained in
      Section~\ref{sec:primitiveops_index}, the index can be determined by
      simply examining the exponent of ${Y_0}_P$, as all $a_I$ are distinct and
      the mapping between the exponent of ${Y_0}_P$ and the index of $Y$ is
      bijective.

    \subsubsection{Overflow}
      \label{sec:indexed_overflow}
      If an indexed type $Y$ has index 0 and the width is $W$, then the value
      in the primary field ${Y_0}_P$ would be stored as an offset from
      $1.5\epsilon^{-1}2^{e_{\max} + 1 - W}$. However,
      \(
        1.5\epsilon^{-1}2^{e_{\max} + 1 - W} > 2^{e_{\max} + 1 + (p - W)}
            > 2 \cdot 2^{e_{\max}}
      \) since $W < p - 2$, so it would be out of the range of the
      floating-point system and not representable. Before discussing the
      solution to this overflow problem, take note of Theorem
      \ref{thm:overflow}.

      \begin{samepage}
      \begin{thm}
        If $2 W > p + 1$, then for any indexed type $Y$ of index $I$ and any ${Y_k}_P$ such that $I + k \geq 1$, $|{Y_k}_P| < 2^{e_{\max}}$.
        \label{thm:overflow}
      \end{thm}
    \end{samepage}

      \begin{proof}
        $a_1 = e_{\max} + 1 - 2 W$ by \eqref{eq:a}, therefore $a_1 < e_{\max} - p$ using $2W > p+1$ and since all quantities are integers, $a_1 \leq e_{\max} - p - 1$. If $I + k \geq 1$, $a_{I + k} \leq a_1 \leq e_{\max} - p - 1$ by \eqref{eq:a}.

        ${Y_k}_P$ is kept within the range $(\epsilon^{-1} 2^{a_{I + k}}, 2 \epsilon^{-1} 2^{a_{I + k}})$, therefore
        \begin{equation*}
          |{Y_k}_P| < 2 \epsilon^{-1} 2^{a_{I + k}} \leq 2^{1 + p} 2^{e_{\max} - 1 - p} = 2^{e_{\max}}
        \end{equation*}
      \end{proof}
      By Theorem \ref{thm:overflow}, if $2 W > p + 1$ then the only primary
      field that could possibly overflow is a primary field corresponding to
      bin 0, and all other primary fields have exponent less than $e_{\max}$.
      Therefore, we require $2 W > p + 1$ and express the value of the primary
      field corresponding to bin 0 as a scaled offset from
      $1.5\cdot2^{e_{\max}}$. Note that this preserves uniqueness of the
      exponent of the primary field corresponding to bin 0 because no other
      primary field has an exponent of $e_{\max}$. The value
      ${\mathcal{Y}_0}_P$ stored in the primary field ${Y_0}_P$ of an indexed
      type $Y$ of index 0 is expressed in \eqref{eq:pri0}.
      \begin{equation}
        {\mathcal{Y}_0}_P = 2^{p - W + 1}({Y_0}_P - 1.5\cdot2^{e_{\max}})
        \label{eq:pri0}
      \end{equation}

      Although the primary field corresponding to bin 0 is scaled, the same restriction \eqref{eq:totalfreq} on $n$ applies here as it does in the normal case. Therefore, the partial sums in reproducible summation can grow much larger ($(\epsilon^{-1} - 1)2^{p - W - 1}$ times larger) than the overflow threshold and then cancel back down. In fact, as long as the sum itself is below overflow (beyond the margin of error), the summands are finite, and $n \leq (\epsilon^{-1} - 1)2^{p - W - 2}$, the reproducible summation won't overflow. However, if the inputs to summation are already infinite, the summation will overflow. In the case of a dot product, overflow does not occur due to partial sums, but will occur if the pairwise products themselves overflow (overflow only occurs during multiplication).

    \subsubsection{Gradual Underflow}
      \label{sec:indexed_underflow_gradual}
      Here we consider the effects of gradual underflow on algorithms described
      in \cite{repsum} and how the indexed type allows these algorithms to work
      correctly. Although we will discuss abrupt underflow briefly in the next section, we will consider only gradual underflow in the remainder of the work.

      Algorithms \ref{alg:deposit} for adding a floating point input to an
      indexed type in Section~\ref{sec:primitiveops_deposit} and
      Algorithm~\ref{alg:renorm} for renormalizing an indexed type in
      Section~\ref{sec:primitiveops_renormalize} require that the primary
      fields ${Y_k}_P$ are normalized to work correctly. Theorem
      \ref{thm:underflowufp} shows that the primary fields should always be
      normalized.

      \begin{samepage}
      \begin{thm}
        For any primary field ${Y_k}_P$ of an indexed type $Y$ of index $I$ where ${Y_k}_P \in (\epsilon^{-1} 2^{a_{I + k}}, 2 \epsilon^{-1} 2^{a_{I + k}})$ (${Y_0}_P \in (2^{e_{\max}}, 2 \cdot 2^{e_{\max}})$ if $Y$ has index 0), ${Y_k}_P$ is normalized.
        \label{thm:underflowufp}
      \end{thm}
      \end{samepage}

      \begin{proof}
        By \eqref{eq:binmin},
        \[
        a_{I + k} \geq a_{i_{\max}} = e_{\min} - p + 2 + \bigl((e_{\max} - e_{\min} + p - 1) \mod W\bigr) \geq e_{\min} - p + 2
        \]

        Because ${Y_k}_P \in (\epsilon^{-1} 2^{a_{I + k}}, 2 \epsilon^{-1} 2^{a_{I + k}})$ we have $\exp({Y_k}_P) = a_{I + k} + p > e_{\min} + 1$ so ${Y_k}_P$ is normalized.
      \end{proof}

      Algorithms \ref{alg:depositrestricted} and \ref{alg:deposit} in Section \ref{sec:primitiveops_deposit} rely on
      setting the last bit of intermediate results before adding them to
      ${Y_k}_P$ in order to fix the direction of the rounding mode. However, if
      $r$ is the quantity to be added to ${Y_k}_P$, $\ulp(r)$ must be less than
      rounding error in ${Y_k}_P$ when added to ${Y_k}_P$.
      Mathematically, we will require $\ulp(r) < 0.5\ulp({Y_k}_P)$ in order to
      prove Theorem~\ref{thm:ddeposit} about the correctness of
      Algorithm~\ref{alg:deposit}.  This is why we must enforce $a_{i_{\max}}
      \geq e_{\min} - p + 2$ so that the least significant bit of the least bin
      is larger than twice the smallest denormalized number.

      This does not mean it is impossible to sum the input in the denormalized range. One simple way
      the algorithm could be extended to denormalized inputs would be to scale
      the least bins up, analogously to the way we handled overflow. Due to the
      relatively low priority for accumulating denormalized values, this method
      was not implemented in ReproBLAS. With respect to taking a reproducible dot product, we do not extend the underflow threshold to ensure the products of tiny values do not underflow. The underflow threshold is the same as in normal reproducible summation. Others may implement these features if they think it is important.


    \subsubsection{Abrupt Underflow}
      \label{sec:indexed_underflow_abrupt}
      If underflow is abrupt, several approaches may be taken to modify the
      given algorithms to ensure reproducibility. We discuss these approaches in this section, but the rest of the work will consider only gradual underflow.

      The most straightforward approach would be to accumulate input in the
      denormalized range by scaling the smaller inputs up. This has the added
      advantage of increasing the accuracy of the algorithm. A major
      disadvantage to this approach is the additional branching cost incurred
      due to the conditional scaling.

      A more efficient way to solve the problem would be to set the least bin
      to have $a_{i_{\max}} = e_{\min}$. This means that all the values smaller
      than $2^{e_{\min}}$ will not be accumulated. 
      This could be accomplished either
      by keeping the current binning scheme and having the least bin be of a
      width not necessarily equal to $W$, or by shifting all other bins to be
      greater. The disadvantage of shifting the other bins is that it may cause
      multiple greatest bins to overflow, adding multiple scaling cases.
      Setting such a least bin would enforce the condition that no underflow
      occurs since all intermediate sums are either $0$ or greater than the
      underflow threshold. The denormal range would be discarded.

      Setting the least bin is similar to zeroing
      out the mantissa bits of each summand
      that correspond to values $2^{(e_min-1)}$ or smaller. However, performing
      such a bitwise manipulation would likely be more computationally intensive
      and would not map as intuitively to our binning process.

      In the case that reproducibility is desired on heterogeneous machines,
      where some processors may handle underflow gradually and others abruptly,
      the approach of setting a least bin is recommended. The indexed sum using
      this scheme does not depend on whether or not underflow is handled
      gradually or abruptly, so the results will be the same regardless of
      where they are computed.

    \subsubsection{Exceptions}
      \label{sec:indexed_exceptions}
      Indexed types are capable of representing exceptional cases such as
      \texttt{NaN} (Not a Number) and \texttt{Inf} (Infinity). An indexed type
      $Y$ stores its exception status in its first primary field ${Y_0}_P$.

      A value of $0$ in ${Y_0}_P$ indicates that nothing has been added to
      ${Y_0}_P$ yet (${Y_0}_P$ is initialized to $0$).

      Since the ${Y_k}_P$ are kept within the range
      \(
      	(\epsilon^{-1}  2^{a_{I + k}}, 2 \epsilon^{-1} 2^{a_{I + k}})
      \) (where $I$ is the index) and are
      normalized (by Theorem \ref{thm:underflowufp}), we have

      \begin{equation*}
        {Y_k}_P > 2^{e_{\min}}
      \end{equation*}

      Therefore the value of $0$ in a primary field is unused in any previously
      specified context and may be used as a sentinel value. (As the exponent
      of $0$ is distinct from the exponent of normalized values, the bijection
      between the index of an indexed type $Y$ and the exponent of ${Y_0}_P$ is
      preserved)

      A value of \texttt{Inf} or \texttt{-Inf} in ${Y_0}_P$ indicates that one or more \texttt{Inf} or \texttt{-Inf} (and no other exceptional values) have been added to $Y$ respectively.

      A value of \texttt{NaN} in ${Y_0}_P$ indicates that one or more \texttt{NaN}s have been added to $Y$ or one or more of both \texttt{Inf} and \texttt{-Inf} have been added to $Y$. Note that there are several types of \texttt{NaN}. We do not differentiate among them. We consider all types \texttt{NaN} as identically \texttt{NaN}.

      As the ${Y_k}_P$ are kept finite to store finite values, \texttt{Inf}, \texttt{-Inf}, and \texttt{NaN} are unused in any previously specified context and are valid sentinel values. (As the exponent of \texttt{Inf}, \texttt{-Inf}, and \texttt{NaN} is distinct from the exponent of finite values, the bijection between the index of an indexed type $Y$ and the exponent of ${Y_0}_P$ is preserved)

      This behavior follows the behavior for exceptional values in IEEE
      754-2008 floating point arithmetic. The result of adding some exceptional
      values using floating-point arithmetic therefore matches the result
      obtained from indexed summation. As \texttt{Inf}, \texttt{-Inf}, and
      \texttt{NaN} add associatively, this behavior is reproducible.

      Note that, as will be explained in Section~\ref{sec:primitiveops},
      as long as the number of inputs is limited by $n \leq (\epsilon^{-1} - 1)2^{p-W-2}$ (approximately $2^{64}$ for \texttt{double} and $2^{33}$ for \texttt{float})
      and all the inputs are finite, there will be no intermediate \texttt{NaN}
      or $\pm \texttt{Inf}$ during the computation.
      For example, given $x \in \F$ the biggest representable value below the
      overflow threshold, our algorithm will compute a result of exactly $0$ for
      the sum of input vector $[x,x,-x,-x]$ regardless of the order of evaluation.
      On the other hand, a standard recursive summation algorithm returns either
      $((x+x)-x)-x=\texttt{Inf}$, $((-x-x)+x)+x=-\texttt{Inf}$, $((x-x)+x)-x = 0$, 
      or $((x + x) + (-x-x)) = \texttt{NaN}$ depending on the order of evaluation.

      It should also be noted here that it is possible to achieve a final result of
      $\pm \texttt{Inf}$ when ${Y_0}_P$ is finite. This is due to
      the fact that the indexed representation can express values outside of
      the range of the floating point numbers that it is composed with. More
      specifically, it is possible for the value $\mathcal{Y}$ represented by
      the indexed type $Y$ to satisfy $|\mathcal{Y}| \geq 2 \cdot
      2^{e_{\max}}$. The condition that $\mathcal{Y}$ is not representable is
      discovered when calculating $\mathcal{Y}$ (converting $Y$ to a floating
      point number). The methods used to avoid overflow and correctly return
      the \texttt{Inf} or \texttt{-Inf} are discussed in Section
      \ref{sec:primitiveops_conv2float}.

      There are several ways that \texttt{Inf}, \texttt{-Inf}, and \texttt{NaN} could be handled reproducibly. We have chosen to handle these values analagously to how they are handled in standard recursive summation. This results in an additional performance cost due to special branches for these special values. Another way to handle these values would be to always return \texttt{NaN} when any summand is \texttt{Inf}, \texttt{-Inf}, or \texttt{NaN}. This would result in less branching.

    \subsection{Indexed Sum}
      \label{sec:indexed_sum}
      We have previously explained the indexed type, a data structure we will use for reproducible summation. We now define a quantity that can be expressed using the indexed type, called the \textbf{indexed sum}. The goal for Section \ref{sec:primitiveops} will be to show that we can indeed compute this quantity. Ultimately, Theorems \ref{thm:addfloattoindexed} and \ref{thm:sum} will prove that Algorithms \ref{alg:addfloattoindexed} and \ref{alg:sum} (respectively) can indeed compute the indexed sum. Here we focus on the definition of an indexed sum. As further motivation for computing the indexed sum, we show that if an algorithm returns the indexed sum of its inputs, it is reproducible.
      \begin{definition}
      Assume $n \leq (\epsilon^{-1} - 1)2^{p - W - 2}$. The $K$-fold \textbf{indexed sum} of finite $x_0, ..., x_{n - 1} \in \F$ is defined to be a $K$-fold indexed type $Y$ such that:
      \begin{align}
        &{Y_k}_P \in \begin{cases}[1.5  \epsilon^{-1} 2^{a_{I + k}}, 1.75  \epsilon^{-1} 2^{a_{I + k}}) \text{ if } I + k > 0 \\ [1.5 \cdot 2^{e_{\max}}, 1.75 \cdot 2^{e_{\max}}) \text{ if } I + k = 0\end{cases} \nonumber\\
        &\mathcal{Y}_k = \sum\limits_{j = 0}^{n - 1}d(x_j, I + k)\nonumber\\
        & I\text{ is the greatest integer such that }\max(|x_j|) < 2^{b_I} \text{ and } I \leq i_{\max}\nonumber\\\label{eq:indexed_sum}
      \end{align}
      The $K$-fold indexed sum of $x_0, ..., x_{n - 1} \in \F$ (with at least one exceptional value \texttt{Inf}, \texttt{-Inf}, or \texttt{NaN}) is defined to be a $K$-fold indexed type such that
      \begin{equation}
        {Y_0}_P = \begin{cases}\texttt{Inf} \text{ if there is at least one \texttt{Inf} and no other exceptional values}\\ \texttt{-Inf} \text{ if there is at least one \texttt{-Inf} and no other exceptional values}\\ \texttt{NaN}\text{ otherwise}\end{cases} \label{eq:indexed_sum_exceptional}
      \end{equation}
      And the $K$-fold indexed sum of no numbers (the empty sum) is defined to be the $K$-fold indexed type such that
      \begin{align}
        {Y_k}_P = 0\nonumber\\
        {Y_k}_C = 0\nonumber\\
        \label{eq:indexed_sum_zero}
      \end{align}
      \end{definition}
      Notice that in \eqref{eq:indexed_sum}, the value of ${Y_k}_C$ is specified implicitly, because $\mathcal{Y}_k$ is expressed in terms of both ${Y_k}_P$ and ${Y_k}_C$ in \eqref{eq:acc}.

      We now show that the indexed sum is well-defined for finite summands and that each field in the indexed type corresponding to the summands $x_0, ..., x_{n - 1}$ (in any order) is unique. We show this in Lemma \ref{lem:indexed_sum_unique}.
      \begin{samepage}
      \begin{lem}
        Let $Y$ be the indexed sum of some $x_0, ..., x_{n - 1} \in \F$, where each $x_i$ is a finite value and $n \geq 1$.
        Let $\sigma_0, ..., \sigma_{n - 1}$ be some permutation of the first $n$ nonnegative integers such that $\{\sigma_0, ..., \sigma_{n - 1}\} = \{0, ..., n - 1\}$ as sets.
        Let $Z$ be the indexed sum of $x_{\sigma_0}, ..., x_{\sigma_{n - 1}}$.

        For all $k$, $0 \leq k < K$, we have that ${Y_k}_P = {Z_k}_P$ and ${Y_k}_C = {Z_k}_C$.
        \label{lem:indexed_sum_unique}
      \end{lem}
      \end{samepage}

      \begin{proof}
        Since $\max(|x_j|) = \max(|x_{\sigma_j}|)$, both $Y$ and $Z$ have the same index $I$, since $I$ is the greatest integer such that $\max(|x_j|) < 2^{b_I}$ and $I \leq i_{\max}$.

        Using the associativity of addition,
        \begin{equation*}
          \mathcal{Y}_k = \sum\limits_{j = 0}^{n - 1}d(x_j, I + k) = \sum\limits_{j = 0}^{n - 1}d(x_{\sigma_j}, I + k) = \mathcal{Z}_k
        \end{equation*}

        If $I + k \geq 1$, Assume for contradiction that there exists some $k$, $0 \leq k < K$,, such that ${Y_k}_C \neq {Z_k}_C$. Since $\mathcal{Y}_k = \mathcal{Z}_k$, \eqref{eq:acc} yields
        \begin{align*}
          ({Y_k}_P - 1.5 \epsilon^{-1}2^{a_{I + k}}) + (0.25\epsilon^{-1}2^{a_{I + k}}){Y_k}_C &= ({Z_k}_P - 1.5 \epsilon^{-1}2^{a_{I + k}}) + (0.25\epsilon^{-1}2^{a_{I + k}}){Z_k}_C\\
          {Y_k}_P - {Z_k}_P &= (0.25\epsilon^{-1}2^{a_{I + k}})({Z_k}_C - {Y_k}_C)\\
          |{Y_k}_P - {Z_k}_P| &\geq 0.25\epsilon^{-1}2^{a_{I + k}}
        \end{align*}

        Since ${Y_k}_P \in [1.5  \epsilon^{-1} 2^{a_{I + k}}, 1.75  \epsilon^{-1} 2^{a_{I + k}})$, ${Z_k}_P \not\in [1.5  \epsilon^{-1} 2^{a_{I + k}}, 1.75  \epsilon^{-1} 2^{a_{I + k}})$, a contradiction.

        Therefore, we have that ${Y_k}_C = {Z_k}_C$. Along with the fact that $\mathcal{Y}_k = \mathcal{Z}_k$, application of \eqref{eq:acc} yields that ${Y_k}_P = {Z_k}_P$.

        If $I = 0$, assume for contradiction that ${Y_0}_C \neq {Z_0}_C$. Since $\mathcal{Y}_0 = \mathcal{Z}_0$, \eqref{eq:acc} and \eqref{eq:pri0} yield
        \begin{align*}
          2^{p - W + 1}({Y_0}_P - 1.5\cdot2^{e_{\max}}) + (0.25\epsilon^{-1}2^{a_{0}}){Y_0}_C &= 2^{p - W + 1}({Z_0}_P - 1.5\cdot2^{e_{\max}}) + (0.25\epsilon^{-1}2^{a_{0}}){Z_0}_C\\
          {Y_0}_P - {Z_0}_P &= 2^{W - p - 1}(0.25\epsilon^{-1}2^{a_{0}})({Z_0}_C - {Y_0}_C)\\
          |{Y_0}_P - {Z_0}_P| &\geq 2^{W - p - 1}(0.25\epsilon^{-1}2^{a_{0}})
        \end{align*}
        and by \eqref{eq:a} and \eqref{eq:b}, we have
        \begin{equation*}
          |{Y_0}_P - {Z_0}_P| \geq 0.25\cdot2^{e_{\max}}
        \end{equation*}

        Since ${Y_0}_P \in [1.5  \cdot2^{e_{\max}}, 1.75  \cdot2^{e_{\max}})$, ${Z_k}_P \not\in [1.5  \cdot2^{e_{\max}}, \cdot2^{e_{\max}})$, a contradiction.

        Therefore, we have that ${Y_0}_C = {Z_0}_C$. Along with the fact that $\mathcal{Y}_0 = \mathcal{Z}_0$, application of \eqref{eq:acc} together with \eqref{eq:pri0} yields that ${Y_0}_P = {Z_0}_P$.
      \end{proof}

      With Lemma \ref{lem:indexed_sum_unique}, it is not hard to see that the more inclusive Theorem \ref{thm:indexed_sum_unique} applies to the indexed sum.

      \begin{samepage}
      \begin{thm}
        Let $Y$ be the indexed sum of some $x_0, ..., x_{n - 1} \in \F$.
        Let $\sigma_0, ..., \sigma_{n - 1}$ be some permutation of the first $n$ nonnegative integers such that $\{\sigma_0, ..., \sigma_{n - 1}\} = \{0, ..., n - 1\}$ as sets.
        Let $Z$ be the indexed sum of $x_{\sigma_0}, ..., x_{\sigma_{n - 1}}$.

        If all $x_0$ are finite or $n = 0$, we have that for all $k$, $0 \leq k < K$, ${Y_k}_P = {Z_k}_P$ and ${Y_k}_C = {Z_k}_C$. Otherwise, ${Y_0}_P = {Z_0}_P$ and ${Y_0}_P$ is exceptional.
        \label{thm:indexed_sum_unique}
      \end{thm}
      \end{samepage}
      \begin{proof}
        If all $x_i$ are finite and $n \geq 1$, then the claim holds by Lemma \ref{lem:indexed_sum_unique}. If $n = 0$, then by \eqref{eq:indexed_sum_zero} we have that
for all $k$, $0 \leq k < K$, ${Y_k}_P = {Z_k}_P = 0$ and ${Y_k}_C = {Z_k}_C = 0$.

        If at least one $x_i$ is exceptional, then since the conditions in \eqref{eq:indexed_sum_exceptional} depend only on the number of each type of exceptional value and not on their order, we have that ${Y_0}_P = {Z_0}_P$. Since all of the possible cases are exceptional, ${Y_0}_P$ is exceptional.
      \end{proof}

    Theorem \ref{thm:indexed_sum_unique} implies that any algorithm that can compute the indexed sum of a list of floating point numbers is a reproducible summation algorithm, as the indexed sum is well-defined, unique, and independent of the ordering of the summands.
